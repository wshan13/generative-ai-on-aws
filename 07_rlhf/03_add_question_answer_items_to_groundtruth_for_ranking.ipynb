{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JPOTj7tlI2t"
   },
   "source": [
    "# 인간 피드백으로 얻은 항목 추가\n",
    "\n",
    "![Pipeline](img/generative_ai_pipeline_rlhf_plus.png)\n",
    "\n",
    "![RLHF](img/rlhf_qa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sqhMqpRqlI2v",
    "outputId": "9ae412be-97c5-486e-838a-1c85db49cacf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=33163763712, available=31108259840, percent=6.2, used=1630367744, free=28735410176, active=525201408, inactive=3470077952, buffers=4329472, cached=2793656320, shared=638976, slab=181776384)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "print(notebook_memory)\n",
    "\n",
    "if notebook_memory.total < 32 * 1000 * 1000 * 1000:\n",
    "    print('*******************************************')\n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "evqH-fZ6lI2x",
    "outputId": "54cde3e8-7bbb-4670-ab00-88effa4c8a7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tmfs91f8lI2x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# 아마존 파이썬 SDK 클라이언트\n",
    "sagemaker = boto3.client(\"sagemaker\", region)\n",
    "#comprehend = boto3.client(\"comprehend\", region)\n",
    "a2i = boto3.client(\"sagemaker-a2i-runtime\")\n",
    "s3 = boto3.client(\"s3\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an228roplI2x"
   },
   "source": [
    "# 이전에 생성된 `augmented_ai_flow_definition_arn` 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZFDJpZ9DlI2x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r augmented_ai_flow_definition_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1IyEsPiXlI2y",
    "outputId": "fdd14987-da69-4995-f329-dd837bba9117",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:843956416240:flow-definition/fd-ranking-1aa49519-cb36-4b67-abe7-983f5c40d5d8\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_flow_definition_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DMtWjgmMlI2y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = [\n",
    "    {\n",
    "        \"prompt\": \"\"\"\n",
    "            Chris: Hey Antje and Shelbee! Do you want to write a book on generative AI?\n",
    "            Antje: That sounds fun. What do you think, Shelbee?\n",
    "            Shelbee: Of course! Should we title the book, “Generative AI on AWS”?\n",
    "            Chris: Yes!\n",
    "            Antje: Yes!\n",
    "        \"\"\",\n",
    "        \"responses\": [\n",
    "            \"\"\"\n",
    "            Chris, Shelbee, and Antje agree to write a book titled, “Generative AI on AWS”.\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris asks Antje and Shelbee if they want to write a book on generative AI. They agree to write the book.\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris asks Antje and Shelbee to write a book. They agree.\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris, Antje, and Shelbee decide not to write a book.\n",
    "            \"\"\"\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CvXZTga5lI2y",
    "outputId": "7970d998-d8d0-4c34-8e72-d1589b746312",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item: \"{'prompt': '\\n            Chris: Hey Antje and Shelbee! Do you want to write a book on generative AI?\\n            Antje: That sounds fun. What do you think, Shelbee?\\n            Shelbee: Of course! Should we title the book, “Generative AI on AWS”?\\n            Chris: Yes!\\n            Antje: Yes!\\n        ', 'responses': ['\\n            Chris, Shelbee, and Antje agree to write a book titled, “Generative AI on AWS”.\\n            ', '\\n            Chris asks Antje and Shelbee if they want to write a book on generative AI. They agree to write the book.\\n            ', '\\n            Chris asks Antje and Shelbee to write a book. They agree.\\n            ', '\\n            Chris, Antje, and Shelbee decide not to write a book.\\n            ']}\"\n",
      "*** ==> Starting human loop with name: 75fd992e-867c-4741-99f2-ace6ffa50435  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_loops_started = []\n",
    "\n",
    "for item in items:\n",
    "    print(f'Processing item: \"{item}\"')\n",
    "\n",
    "    humanLoopName = str(uuid.uuid4())\n",
    "    inputContent = {\"taskObject\": item}\n",
    "    start_loop_response = a2i.start_human_loop(\n",
    "        HumanLoopName=humanLoopName,\n",
    "        FlowDefinitionArn=augmented_ai_flow_definition_arn,\n",
    "        HumanLoopInput={\"InputContent\": json.dumps(inputContent)},\n",
    "    )\n",
    "\n",
    "    human_loops_started.append(humanLoopName)\n",
    "\n",
    "    print(f\"*** ==> Starting human loop with name: {humanLoopName}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p1Oyg4K-lI2z",
    "outputId": "4c616344-e2e7-43ba-d71e-e1e4c94ef297",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_loops_started' (list)\n"
     ]
    }
   ],
   "source": [
    "%store human_loops_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O22sMeGNlI2z"
   },
   "source": [
    "# 휴먼 루프 상태 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dgrkpNEdlI2z",
    "outputId": "2b3aa338-6691-4268-9395-672c2f3776e4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 75fd992e-867c-4741-99f2-ace6ffa50435\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-843956416240/ground-truth-star-rating-results/fd-ranking-1aa49519-cb36-4b67-abe7-983f5c40d5d8/2024/08/25/01/53/19/75fd992e-867c-4741-99f2-ace6ffa50435/output.json'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AzRo5czlI20",
    "tags": []
   },
   "source": [
    "# 휴먼 루프 작업이 완료될 때까지 기다리기\n",
    "\n",
    "아래 링크로 이동하여, 개인 워크포스(Private Workforce) 설정 시 사용한 이메일과 비밀번호로 로그인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nM79m76IlI20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r augmented_ai_workteam_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uhjAxtIQlI21",
    "outputId": "afad412b-efcb-47fd-f1ad-adcd27d0e7c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:843956416240:workteam/private-crowd/dsoaws\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_workteam_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZeBcFHXAlI21",
    "outputId": "d9dcfe89-1edb-4173-afeb-566f2d121cfd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://d5hmgwn4tg.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmOt2D3dlI21"
   },
   "source": [
    "# 진행하기 전에 위의 링크를 클릭하여 데이터를 라벨링해야 합니다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97kypR8klI22"
   },
   "source": [
    "# 라벨링 시작하기\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-start-working.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v528sZ9lI22"
   },
   "source": [
    "# 레이블 선택하기\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-select-label.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGUnRta7lI22",
    "tags": []
   },
   "source": [
    "# 루프 완료\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-finished-task.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0_zfAkblI22"
   },
   "source": [
    "# 휴먼 루프 완료 여부 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JD5WUvt6lI22",
    "outputId": "ffd3de32-c534-4a99-b635-121b9d4e9aff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://d5hmgwn4tg.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "w0hfTNjIlI22",
    "outputId": "9f84b5be-6053-476c-a6a6-d207a99c4bb4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 75fd992e-867c-4741-99f2-ace6ffa50435\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-843956416240/ground-truth-star-rating-results/fd-ranking-1aa49519-cb36-4b67-abe7-983f5c40d5d8/2024/08/25/01/53/19/75fd992e-867c-4741-99f2-ace6ffa50435/output.json'}\n",
      "\n",
      "Completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "    while resp[\"HumanLoopStatus\"] != \"Completed\":\n",
    "        print(f\"Waiting for HumanLoop to complete.\")\n",
    "        time.sleep(10)\n",
    "        resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)\n",
    "        print(f\"Completed!\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUYPk-LslI23",
    "tags": []
   },
   "source": [
    "# 안간 레이블 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKxqlNcPlI23",
    "tags": []
   },
   "source": [
    "작업이 완료되면, 아마존 그라운드 트루스는 결과를 지정된 S3 버킷에 저장하고 CloudWatch 이벤트를 보냅니다. 아래는 그라운드 트루스에서 jsonlines 형식으로 레이블이 매겨진 샘플 항목입니다.\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    " \"inputContent\": {\"taskObject\": {\n",
    "                         \"prompt\": \"Who is Angela Merkel's favorite President of the United States?\",\n",
    "                         \"responses\": [\"George Clinton\", \"Barack Obama\"]}\n",
    "                 },\n",
    " \"humanAnswers\": [{\"answerContent\": {\n",
    "                        \"ranking_1\": \"1\", # 첫번째 응답 순위 (1=최우수)\n",
    "                        \"ranking_2\": \"2\"  # 두번째 응답 순위 (2=최악)\n",
    "                 }}]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZSj31jElI23"
   },
   "source": [
    "# 강화 학습/PPO 학습을 위한 인간이 단 주석 데이터 준비하기\n",
    "그라운드 트루스에서 데이터를 가져와 모든 순위에 대해 이진 보상(-1, 1)으로 변환합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "이진 보상 변환 전:\n",
    "```\n",
    "prompt                                                              response           ranking\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     George Clinton     1   # 최우수\n",
    "Who is Angela Merkel's favorite President of the United States?     Barack Obama       2   # 최악\n",
    "```\n",
    "\n",
    "이진 보상 변환 후:\n",
    "```\n",
    "prompt                                                              response           reward\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     George Clinton     0   # 낮은 보상\n",
    "Who is Angela Merkel's favorite President of the United States?     Barack Obama       1   # 높은 보상\n",
    "```\n",
    "\n",
    "이진 보상 변환 후:\n",
    "```\n",
    "prompt                                                              response                               highest_ranked_response\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     [\"George Clinton\", \"Barack Obama\"]     [0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xrc8fnaDlI23",
    "tags": []
   },
   "source": [
    "# 참고: 아래에 아무것도 표시되지 않으면, 이전 노트북에서 그라운드 트루스에 대한 데이터 라벨링하는 작업을 완료해야 합니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Utw8ajInlI23",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "human_feedback_items = []\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    human_feedback_s3_uri = resp[\"HumanLoopOutput\"][\"OutputS3Uri\"]\n",
    "    split_string = re.split(\"s3://\" + bucket + \"/\", resp[\"HumanLoopOutput\"][\"OutputS3Uri\"])\n",
    "    key = split_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "    json_output = json.loads(content)\n",
    "\n",
    "    prompt = json_output[\"inputContent\"]['taskObject']['prompt']\n",
    "    responses = json_output[\"inputContent\"]['taskObject']['responses']\n",
    "    response_1_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_1_ranking']\n",
    "    response_2_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_2_ranking']\n",
    "\n",
    "    human_feedback_item_1 = (prompt, responses[0], response_1_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_1)\n",
    "    human_feedback_item_2 = (prompt, responses[1], response_2_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xVUyy7aRlI24",
    "outputId": "bdd32b9b-343a-4225-de52-74bac3397bcc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris asks Antje and Shelbee if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "1  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...       2  \n",
       "1  \\n            Chris asks Antje and Shelbee if ...       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items = pd.DataFrame(human_feedback_items, columns=['prompt', 'response', 'ranking'])\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neaSaxCAlI24",
    "tags": []
   },
   "source": [
    "# 순위를 0 또는 1 보상으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "j9tPYriTlI24",
    "outputId": "aef807fb-6c47-46e8-ff77-c1097191df42",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris asks Antje and Shelbee if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "1  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...       0  \n",
       "1  \\n            Chris asks Antje and Shelbee if ...       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rankings = 2\n",
    "df_human_feedback_items['response'] = df_human_feedback_items['response'].apply(lambda response: str(response))\n",
    "df_human_feedback_items['ranking'] = df_human_feedback_items['ranking'].apply(lambda ranking: str(abs(int(ranking) - num_rankings)))\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AAcCLDHZlI24",
    "outputId": "86474c39-394e-4c63-d628-1d071469094b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>0,1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...     0,1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt = df_human_feedback_items.groupby('prompt', as_index=False).agg({'prompt' : 'first', 'response' : ','.join, 'ranking' : ','.join})\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oygz-nP1lI25",
    "outputId": "15084924-a6da-4018-f5d6-a1d6a5523760",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>[\\n            Chris,  Shelbee,  and Antje agr...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  [\\n            Chris,  Shelbee,  and Antje agr...  [0, 1]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt['response'] = df_human_feedback_items_grouped_by_prompt['response'].apply(lambda response: [s for s in response.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt['ranking'] = df_human_feedback_items_grouped_by_prompt['ranking'].apply(lambda ranking: [int(s) for s in ranking.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eC8LdEzJlI25",
    "outputId": "31f11aff-e510-4481-d10d-3badd794974b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'ranking'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create Dataset objects (Arrow PyTables) from Pandas dataframes\n",
    "human_feedback_dataset = Dataset.from_pandas(df_human_feedback_items_grouped_by_prompt)\n",
    "human_feedback_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "yQZIMjRZlI26",
    "outputId": "4ee5168a-4215-4e46-9101-d266402a73e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_feedback_dataset' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "%store human_feedback_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrpGiXRXlI26"
   },
   "source": [
    "# 계속하기 전에 위의 링크를 클릭하여 데이터를 라벨링해야 합니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "InXTSNhJlI26",
    "outputId": "d6698146-c1b1-42e0-afbb-c4cab5a671b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "\n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "\n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjwT2mn5lI26"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
