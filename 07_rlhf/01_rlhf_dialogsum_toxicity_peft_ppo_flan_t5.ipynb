{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f10b19-c061-42b2-8b42-e3cbafa3b1da",
   "metadata": {
    "id": "d7f10b19-c061-42b2-8b42-e3cbafa3b1da"
   },
   "source": [
    "# FLAN-T5 모델을 강화 학습(PPO) 및 효율적인 매개변수 미세 조정(PEFT)으로 미세 조정하여 덜 유해한 요약문 생성하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef668a-9c51-489b-be47-a07a09ef2289",
   "metadata": {
    "id": "36ef668a-9c51-489b-be47-a07a09ef2289"
   },
   "source": [
    "이 노트북에서는 FLAN-T5 모델을 미세 조정하여 메타 AI의 혐오 발언 보상 모델을 사용해 덜 유해한 내용을 생성할 것입니다. 보상 모델은 주어진 텍스트에 대해 \"혐오 아님\" 또는 \"혐오\"를 예측하는 이진 분류기입니다. 근접 정책 최적화(Proximal Policy Optimization; PPO)을 활용하여 모델의 유해성을 줄이는 미세 조정을 진행할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300816f8-7055-47a4-8d07-38e5d1b73e05",
   "metadata": {
    "id": "300816f8-7055-47a4-8d07-38e5d1b73e05"
   },
   "source": [
    "# ml.m5.2xlarge 인스턴스로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e27dd8-0890-43b3-ba30-8f518dde239f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be296566-ae17-4476-951d-4140ad76cf69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (72.1.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-73.0.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.43.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached setuptools-73.0.1-py3-none-any.whl (2.3 MB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.43.0\n",
      "    Uninstalling wheel-0.43.0:\n",
      "      Successfully uninstalled wheel-0.43.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 72.1.0\n",
      "    Uninstalling setuptools-72.1.0:\n",
      "      Successfully uninstalled setuptools-72.1.0\n",
      "Successfully installed setuptools-73.0.1 wheel-0.44.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c46008-542c-45f1-a80a-7a35d739f97e",
   "metadata": {
    "id": "c6c46008-542c-45f1-a80a-7a35d739f97e",
    "outputId": "8c4d5d50-2d82-45ac-d9ae-ee7d67cee7e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: torchdata in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.7.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (73.0.1)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchdata) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchdata) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m162.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m192.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed cmake-3.30.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.1 torchdata\n",
    "\n",
    "%pip install --disable-pip-version-check -q \\\n",
    "    transformers==4.34.1 \\\n",
    "    datasets==2.12.0 \\\n",
    "    accelerate==0.23.0 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    trl==0.7.1 \\\n",
    "    loralib==0.1.1 \\\n",
    "    peft==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
   "metadata": {
    "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: 트렌스포머 강화 학습 라이브러리\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm: 루프의 진행 상황을 영리한 진행률 표시기로 보여주는 라이브러리\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eea84-8e3a-4487-9692-613977e6c8e3",
   "metadata": {
    "id": "b76eea84-8e3a-4487-9692-613977e6c8e3"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - FLAN-T5 모델을 적재하고, 보상 모델 및 유해성 평가기 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
   "metadata": {
    "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - 데이터를 적재하고 FLAN-T5 모델을 요약에 대한 지침을 활용하여 미세 조정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc0211-4032-4967-946d-3a538829d5c9",
   "metadata": {
    "id": "90dc0211-4032-4967-946d-3a538829d5c9",
    "tags": []
   },
   "source": [
    "여기서는 동일한 허깅 페이스 데이터 세트 [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum)과 사전 학습된 모델 [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)를 계속 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46eb7546-7787-4b49-b780-91c903ed0d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.12.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.17.3)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2024.6.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Installing collected packages: huggingface_hub, datasets\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.12.0\n",
      "    Uninstalling datasets-2.12.0:\n",
      "      Successfully uninstalled datasets-2.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.24.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.21.0 huggingface_hub-0.24.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets huggingface_hub fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e388df01343d404982862e5df935172e"
     ]
    },
    "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
    "outputId": "03a03fb6-e6a9-4ece-d16e-cfd461892739",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188fe6f7b22a4ad3934e9c0987990fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07a49a2e969473b91f5aa8cc3ba496a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f7c2544efe4149ba82624e3301547c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/442k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa460d335944127b54fe066afcd6580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570652279cb545eaa278e82fac2ad822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2529cfca2d94dba83f20b5121bf5d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f2d35b6c864478b90356474e52a126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_name=\"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d30d6-6f81-4e52-a81a-3057163ddb0e",
   "metadata": {
    "id": "668d30d6-6f81-4e52-a81a-3057163ddb0e"
   },
   "source": [
    "다음 단계는 데이터 세트를 전처리합니다. 데이터 세트의 일부만 가져온 후, 특정 길이의 대화만 필터링합니다(예제들이 충분히 길면서 읽기 쉽도록 하기 위함입니다). 그런 다음 각 대화에 지침을 추가하고 프롬프트를 토큰화합니다. `input_ids` 필드에는 토큰 ID를 저장하고, `query` 필드에는 프롬프트의 디코딩된 버전을 저장합니다.\n",
    "\n",
    "아래 셀에서 모든 단계를 차례로 수행할 수 있지만, 모든 작업을 `build_dataset`이라는 함수로 정리하는 것이 좋은 습관입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
   "metadata": {
    "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
    "outputId": "78f0f725-7df2-450d-810e-c1ab61510f62",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2164764e9146b9ade6e6e410e0a442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add7b2a6d8a545058e5cfe1201ac6214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b65fc1649ef40b3ac97d641ef1e7128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ff28d51cd74dc4ac76e0160ee832c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d411e63b260b41f7922d7eaf2b8d3e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf513ed472444ddebad1ab72ddbc503a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "\n",
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length,\n",
    "                  input_max_text_length):\n",
    "\n",
    "    # 데이터 세트 적재 (이 실습에서는 \"학습\" 부분만 필요합니다).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "    # 대화의 길이가 input_min_text_length와 input_max_text_length 사이인 대화만 필터링합니다.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # 토크나이저 준비. device_map=\"auto\"를 설정하면 GPU와 CPU 간의 전환이 자동으로 이루어집니다.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    def tokenize(sample):\n",
    "\n",
    "        # 각 대화에 지침을 추가.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "\n",
    "        # 이 지침은 \"query\"라고 불리며, 이는 PPO 라이브러리의 필수 사항입니다.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # 각 대화를 토큰화\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "\n",
    "    # 데이터 세트를 학습용과 테스트용으로 나눕니다.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200,\n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03155e-649b-45bb-a5a0-94edd682c069",
   "metadata": {
    "id": "7d03155e-649b-45bb-a5a0-94edd682c069",
    "tags": []
   },
   "source": [
    "이전 실습에서는 요약에 대한 지침으로 PEFT 모델을 미세 조정했습니다. 노트북에서의 학습은 데이터의 일부에서 수행되었고, 이후에 완전히 학습된 PEFT 모델의 체크포인트를 S3에서 다운로드했습니다.\n",
    "\n",
    "여기에서 동일한 모델 체크포인트를 적재합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d44a53-ea1f-4fa5-89e7-d46e37d19935",
   "metadata": {
    "id": "e1d44a53-ea1f-4fa5-89e7-d46e37d19935",
    "outputId": "132f8fcf-4080-4260-98c9-4710e3680741",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/special_tokens_map.json to peft-dialogue-summary-checkpoint-from-s3/special_tokens_map.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_config.json to peft-dialogue-summary-checkpoint-from-s3/adapter_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer_config.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_model.bin to peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8bea4-addd-4b29-b3af-6db6ea2baeb7",
   "metadata": {
    "id": "dec8bea4-addd-4b29-b3af-6db6ea2baeb7",
    "tags": []
   },
   "source": [
    "모델 항목을 나열하고 크기를 확인합니다(15MB 미만)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4288240d-764b-4c49-8df7-b30b9277adbd",
   "metadata": {
    "id": "4288240d-764b-4c49-8df7-b30b9277adbd",
    "outputId": "592a60d6-35ff-460d-8086-e91f35102a3d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 14M May 15  2023 ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4226923-67c0-4ea6-8e47-030136b2f191",
   "metadata": {
    "id": "f4226923-67c0-4ea6-8e47-030136b2f191"
   },
   "source": [
    "모델 파라미터 수를 추출하는 함수를 준비합니다(이전 실습과 동일합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f06806-a194-4c14-b64d-e31afd7b658c",
   "metadata": {
    "id": "a1f06806-a194-4c14-b64d-e31afd7b658c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\n학습 가능한 모델 파라미터 수: {trainable_model_params}\\n전체 모델 파라미터 수: {all_model_params}\\n학습 가능한 모델 파라미터 비율: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda",
   "metadata": {
    "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda",
    "tags": []
   },
   "source": [
    "원본 FLAN-T5 모델에 어댑터를 추가합니다. 이전 실습에서는 추론을 위해 완전히 학습된 어댑터만 추가했으므로 저순위 적응(LoRA) 구성 사항을 전달할 필요가 없었습니다. 이제 PEFT 모델을 구성할 때 `is_trainable=True`를 설정하여 저순위 적응 구성을 전달해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
   "metadata": {
    "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
    "outputId": "7b431342-7765-49b7-ed08-5f44cfcd9413",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업데이트될 PEFT 모델 파라미터 수:\n",
      "\n",
      "학습 가능한 모델 파라미터 수: 3538944\n",
      "전체 모델 파라미터 수: 251116800\n",
      "학습 가능한 모델 파라미터 비율: 1.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model,\n",
    "                                       './peft-dialogue-summary-checkpoint-from-s3/',\n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       device_map=\"auto\",\n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'업데이트될 PEFT 모델 파라미터 수:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17",
   "metadata": {
    "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17"
   },
   "source": [
    "이 실습에서는 강화 학습(RL)을 사용하여 대규모 언어 모델(LLM)을 미세 조정할 준비를 하고 있습니다. 강화 학습에 대해 실습의 다음 섹션에서 간단히 설명하겠지만, 현재 단계에서는 PPO 모델을 준비하고 지침에 따라 미세 조정된 PEFT 모델을 전달하는 것만 필요합니다. PPO는 보상 모델에 대해 강화 학습 정책을 최적화하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
   "metadata": {
    "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
    "outputId": "eb371fc4-d89d-44be-b7d1-aff8a0d66079",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913ef05-737e-4cdf-9bac-467ee6cf9f76",
   "metadata": {
    "id": "2913ef05-737e-4cdf-9bac-467ee6cf9f76"
   },
   "source": [
    "PPO 동안에는 몇 가지 파라미터만 업데이트됩니다. 특히, `ValueHead`의 파라미터가 업데이트됩니다. 이 클래스 모델에 대한 자세한 정보는 [문서](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model)에서 확인할 수 있습니다. 학습 가능한 파라미터의 수는 $(n+1)*m$으로 계산할 수 있으며, 여기서 $n$은 입력 단위 수(여기서는 $n=768$)이고 $m$은 출력 단위 수(여기서는 $m=1$)입니다. $+1$ 항은 편향(bias)을 고려합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e",
   "metadata": {
    "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e"
   },
   "source": [
    "이제 PPO의 고정된 복사 모델을 만들어야 합니다. 이 모델은 미세 조정되지 않는 참조 모델입니다. 참조 모델은 유해성 제거 전의 대규모 언어 모델을 나타냅니다. 참조 모델의 파라미터는 PPO 학습 동안 업데이트되지 않습니다. 이는 의도된 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
   "metadata": {
    "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
    "outputId": "28660f71-b68b-4e8e-f617-66b3a77ffd26",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업데이트될 참조 모델 파라미터 수:\n",
      "\n",
      "학습 가능한 모델 파라미터 수: 0\n",
      "전체 모델 파라미터 수: 251117569\n",
      "학습 가능한 모델 파라미터 비율: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'업데이트될 참조 모델 파라미터 수:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a14848-e83d-4fdd-bc68-eb770c5951d7",
   "metadata": {
    "id": "e3a14848-e83d-4fdd-bc68-eb770c5951d7",
    "tags": []
   },
   "source": [
    "모든 준비가 끝났습니다. 이제 보상 모델을 준비할 시간입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137",
   "metadata": {
    "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137"
   },
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - 보상 모델 준비\n",
    "\n",
    "**강화 학습**은 에이전트가 환경에서 행동을 취해 누적 보상을 최대화하는 것을 목표로 하는 기계 학습의 한 유형입니다. 에이전트의 행동은 **정책**에 의해 정의됩니다. 강화 학습의 목표는 에이전트가 **보상 함수**를 최대화하는 최적 또는 거의 최적의 정책을 학습하는 것입니다.\n",
    "\n",
    "[이전 섹션](#2.1)에서는 원래 정책이 지침을 학습된 PEFT 모델을 기반으로 했습니다. 이는 유해성 제거 전의 대규모 언어 모델입니다. 이후, 레이블러에게 출력의 유해성에 대해 피드백을 요청할 수 있습니다. 그러나 전체 미세 조정 과정에 레이블러를 사용하는 것은 비용이 많이 들 수 있습니다. 이를 피하기 위한 실용적인 방법은 에이전트가 대화 요약의 유해성을 제거하도록 유도하는 보상 모델을 사용하는 것입니다. 직관적인 접근 방식은 두 개의 클래스(`혐오 아님`과 `혐오`)에 대한 감정 분석을 수행합니다. `혐오 아님` 클래스를 출력으로 얻을 가능성이 높을수록 더 높은 보상을 주는 것입니다.\n",
    "\n",
    "예를 들어, 전체 미세 조정 과정에 레이블러를 사용하는 것이 비용이 많이 들 수 있음을 언급할 수 있습니다. 이를 피하기 위한 실용적인 방법은 보상 모델을 사용하는 것입니다.\n",
    "\n",
    "모델을 활용하여 생성된 피드백을 사용합니다.\n",
    "\n",
    "[메타 AI의 RoBERTa](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) 기반 유해 언어 탐지 모델을 보상 모델로 사용할 것입니다. 이 모델은 **로짓값**을 출력한 다음 두 개의 클래스인 `혐오 아님`과 `혐오`에 대한 확률을 예측합니다. `혐오 아님`의 로짓값을 긍정적인 보상으로 사용합니다. 그런 다음, 이 보상 값을 사용하여 PPO로 모델을 미세 조정합니다.\n",
    "\n",
    "Create the instance of the required model class for the RoBERTa model. You also need to load a tokenizer to test the model. Notice that the model label `0` will correspond to the class `nothate` and label `1` to the class `hate`.\n",
    "\n",
    "RoBERTa 모델의 필요한 모델 클래스 인스턴스를 생성합니다. 모델을 테스트하기 위해 토크나이저를 적재해야 합니다. 모델 레이블 `0`은 `혐오 아님` 클래스에 해당하고, 레이블 `1`은 `혐오` 클래스에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
   "metadata": {
    "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
    "outputId": "63cde3a2-50d2-4b13-eeea-ce225fcf58c6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc91ae8831cc4a19b2a077217d66f37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f7644e6bd745af92b5929067e5888a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cb5d2d1c424c1a8aa95291c88d1dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b580c9a9c944de8ae45835cd33a057e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b37e669227418eb71d82d0dfa64de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d91217066c4f8ea5f32f03c977b5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d68799-a6e8-42d7-8d61-002e47210c18",
   "metadata": {
    "id": "79d68799-a6e8-42d7-8d61-002e47210c18",
    "tags": []
   },
   "source": [
    "유해성이 적은 텍스트를 몇 개 선택하고, 이를 토큰화한 후 모델에 입력합니다. 출력 로짓값, 확률 및 미세 조정에 사용될 보상을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
   "metadata": {
    "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
    "outputId": "646b3e61-184f-43fb-dab2-8e0ae46439ae",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[혐오 아님, 혐오]에 대한 로짓값: [3.578049898147583, -2.9191946983337402]\n",
      "[혐오 아님, 혐오]에 대한 확률값: [0.9984946250915527, 0.0015053176321089268]\n",
      "보상 (`혐오 아님` 로짓값): [3.578049898147583]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"당신은 훌륭한 사람이고 나는 당신을 좋아합니다.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'[혐오 아님, 혐오]에 대한 로짓값: {logits.tolist()[0]}')\n",
    "\n",
    "# [혐오 아님, 혐오]에 대한 확률 출력\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'[혐오 아님, 혐오]에 대한 확률값: {probabilities}')\n",
    "\n",
    "# \"혐오 아님\"에 대한 로짓값을 가져옵니다 - 이것이 보상입니다!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'보상 (`혐오 아님` 로짓값): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f729c5-98c3-4745-96e8-3484670215db",
   "metadata": {
    "id": "63f729c5-98c3-4745-96e8-3484670215db"
   },
   "source": [
    "유해한 댓글을 보여줍니다. 이는 더 유해성이 강하기 때문에 보상이 낮을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
   "metadata": {
    "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
    "outputId": "d1b066fa-4aee-4480-87f7-71c9fbc6a92b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[혐오 아님, 혐오]에 대한 로짓값: [3.5610382556915283, -2.902846574783325]\n",
      "[혐오 아님, 혐오]에 대한 확률값: [0.9984436631202698, 0.0015563026536256075]\n",
      "보상 (`혐오 아님` 로짓값): [3.5610382556915283]\n"
     ]
    }
   ],
   "source": [
    "toxic_text = \"당신은 끔찍한 사람이고 난 당신을 정말 싫어합니다.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'[혐오 아님, 혐오]에 대한 로짓값: {logits.tolist()[0]}')\n",
    "\n",
    "# [혐오 아님, 혐오]에 대한 확률 출력\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'[혐오 아님, 혐오]에 대한 확률값: {probabilities}')\n",
    "\n",
    "# \"혐오 아님\"에 대한 로짓값을 가져옵니다 - 이것이 보상입니다!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'보상 (`혐오 아님` 로짓값): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5",
   "metadata": {
    "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5"
   },
   "source": [
    "허깅 페이스 추론 파이프라인을 설정하여 유해성 판독기 보상 모델 코드를 단순화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
   "metadata": {
    "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
    "outputId": "e63a49fe-f04b-4a1c-de3d-e1c5eb26b173",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무해한 텍스트에 대한 보상 모델 출력:\n",
      "[{'label': 'nothate', 'score': 3.578049898147583}, {'label': 'hate', 'score': -2.9191946983337402}]\n",
      "[{'label': 'nothate', 'score': 0.9984946250915527}, {'label': 'hate', 'score': 0.0015053176321089268}]\n",
      "\n",
      "유해한 텍스트에 대한 보상 모델 출력:\n",
      "[{'label': 'nothate', 'score': 3.5610382556915283}, {'label': 'hate', 'score': -2.902846574783325}]\n",
      "[{'label': 'nothate', 'score': 0.9984436631202698}, {'label': 'hate', 'score': 0.0015563025372102857}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\",\n",
    "                          model=toxicity_model_name,\n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None,  # 모든 점수를 반환합니다.\n",
    "    \"function_to_apply\": \"none\", # \"none\"으로 설정하여 원시 로짓값을 검색합니다.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # 모든 점수를 반환합니다.\n",
    "    \"function_to_apply\": \"softmax\", # \"softmax\"로 설정하여 소프트맥스를 적용하고 확률을 검색합니다.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"무해한 텍스트에 대한 보상 모델 출력:\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"\\n유해한 텍스트에 대한 보상 모델 출력:\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21302d74-59d8-451f-b287-e86245bf3324",
   "metadata": {
    "id": "21302d74-59d8-451f-b287-e86245bf3324"
   },
   "source": [
    "출력은 `혐오 아님`(긍정)와 `혐오`(부정) 클래스의 로짓값입니다. 그러나 PPO는 `혐오 아님` 클래스의 로짓값만을 긍정적인 보상 신호로 사용하여 대규모 언어 모델 출력을 유해성이 낮아지는데 도움을 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
   "metadata": {
    "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
    "outputId": "54eb0acf-2a8e-41b8-d894-96307e9fa138",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.578049898147583}, {'label': 'hate', 'score': -2.9191946983337402}]\n",
      "[{'label': 'nothate', 'score': 0.9984946250915527}, {'label': 'hate', 'score': 0.0015053176321089268}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d11618b-5887-489a-b390-2139e364987f",
   "metadata": {
    "id": "8d11618b-5887-489a-b390-2139e364987f",
    "outputId": "4326ca8f-7988-41c3-9190-a275149ed710",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.5610382556915283}, {'label': 'hate', 'score': -2.902846574783325}]\n",
      "[{'label': 'nothate', 'score': 0.9984436631202698}, {'label': 'hate', 'score': 0.0015563025372102857}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56513033-9bb1-41d5-81e2-54d1249c5c89",
   "metadata": {
    "id": "56513033-9bb1-41d5-81e2-54d1249c5c89",
    "tags": []
   },
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3. - 유해성 평가\n",
    "\n",
    "모델을 미세 조정을 통한 유해성 제거 전후로 평가하려면 [유해성 평가 메트릭](https://huggingface.co/spaces/evaluate-measurement/toxicity)을 설정해야 합니다. **유해성 점수**는 0과 1 사이의 소수점 값으로, 1이 가장 높은 유해성을 의미합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979",
   "metadata": {
    "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b557b7d1d285420f9dbf1f5ff8e7c9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\",\n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fbc47-c5c2-469a-b5f2-6407e8f0bfde",
   "metadata": {
    "id": "840fbc47-c5c2-469a-b5f2-6407e8f0bfde",
    "tags": []
   },
   "source": [
    "[2.2](#2.2) 섹션에서 사용한 문장들에 대한 유해성을 계산해 보십시오. 유해성 점수는 보상 모델에서 직접 반환된 `혐오` 클래스의 확률입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
   "metadata": {
    "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
    "outputId": "4d19af2e-1123-428f-9a3d-9e2f87de6fb8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무해한 텍스트에 대한 유해성 점수:\n",
      "[0.0015053176321089268]\n",
      "\n",
      "유해한 텍스트에 대한 유해성 점수:\n",
      "[0.0015563025372102857]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "print(\"무해한 텍스트에 대한 유해성 점수:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\n유해한 텍스트에 대한 유해성 점수:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e835b-14b9-4646-b1c9-c975ef3ea944",
   "metadata": {
    "id": "7d3e835b-14b9-4646-b1c9-c975ef3ea944",
    "tags": []
   },
   "source": [
    "이 평가기는 [2.1](#2.1) 섹션에서 준비한 대화의 유해성을 계산하는 데 사용될 수 있습니다. 테스트 데이터 세트(`dataset[\"test\"]`), 그 섹션에서 사용한 동일한 토크나이저, [2.2](#2.2) 섹션에서 준비한 고정된 PEFT 모델, 그리고 독성 평가기를 전달해야 합니다. 필요한 단계를 `evaluate_toxicity` 함수로 래핑하는 것이 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3",
   "metadata": {
    "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model,\n",
    "                      toxicity_evaluator,\n",
    "                      tokenizer,\n",
    "                      dataset,\n",
    "                      num_samples):\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "\n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # 평균 및 표준 편차는 np를 사용하여 계산.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed269c3-dbd7-4d45-bc44-c6ab6d4ae141",
   "metadata": {
    "id": "aed269c3-dbd7-4d45-bc44-c6ab6d4ae141",
    "tags": []
   },
   "source": [
    "이제 모델의 유해성을 미세 조정을 통한 유해성 제거 전과 후에 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
   "metadata": {
    "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
    "outputId": "6796a423-2279-40aa-cf12-32ab754f2da0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:23,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유해성 제거 전 집계된 유해성 점수 [평균, 표준편차]: [0.04217579639622603, 0.039388845535532825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model,\n",
    "                                                                          toxicity_evaluator=toxicity_evaluator,\n",
    "                                                                          tokenizer=tokenizer,\n",
    "                                                                          dataset=dataset[\"test\"],\n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'유해성 제거 전 집계된 유해성 점수 [평균, 표준편차]: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0",
   "metadata": {
    "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - 요약문에 대한 유해성을 제거하기 위해 미세 조정 수행\n",
    "PPO을 사용하여 보상 모델에 대해 강화 학습 정책을 최적화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516e318-8fce-4ca7-bf19-b7baf5255480",
   "metadata": {
    "id": "5516e318-8fce-4ca7-bf19-b7baf5255480"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 - `PPOTrainer` 초기화\n",
    "\n",
    " 설정 매개변수를 설정합니다. `ppo_model`과 토크나이저를 적재합니다. 또한, `ref_model`의 고정된 버전을 적재합니다. 첫 번째 모델은 최적화되며, 두 번째 모델은 쿨백-라이블러(Kullback-Leibler; KL) 발산을 계산하기 위해 참조 모델로 사용됩니다. 이는 PPO 학습에서 추가 보상 신호로 작용하여 최적화된 모델이 원래 대규모 언어 모델에서 너무 벗어나지 않도록 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
   "metadata": {
    "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "# 다음 줄을 주석 해제하여 collator를 테스트할 수 있습니다.\n",
    "# test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "# print(f'Collator input: {test_data}')\n",
    "# print(f'Collator output: {collator(test_data)}')\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config,\n",
    "                         model=ppo_model,\n",
    "                         ref_model=ref_model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset[\"train\"],\n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7352d-53fd-41d8-b438-cfcc9979b0c7",
   "metadata": {
    "id": "56c7352d-53fd-41d8-b438-cfcc9979b0c7"
   },
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - 모델 미세 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62",
   "metadata": {
    "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62"
   },
   "source": [
    "미세 조정 루프는 다음 주요 단계로 구성됩니다.\n",
    "1. 정책 대규모 언어 모델(PEFT 모델)에서 쿼리 응답을 가져옵니다.\n",
    "2. 유해 언어 탐지 RoBERTa 모델에서 쿼리와 응답의 감정을 가져옵니다.\n",
    "3. (쿼리, 응답, 보상) 삼중 항목을 사용하여 PPO로 정책을 최적화합니다.\n",
    "\n",
    "학습이 진행 중이면 다음과 같은 메트릭이 나타납니다.\n",
    "* `objective/kl`: KL 발산을 최소화합니다.\n",
    "* `ppo/returns/mean`: 반환되는 평균을 최대화합니다.\n",
    "* `ppo/policy/advantages_mean`: 이점을 최대화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01536b7e-2f0f-4986-a97c-6ecfabf518d4",
   "metadata": {
    "id": "01536b7e-2f0f-4986-a97c-6ecfabf518d4",
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSAyMC0zMCBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
   "metadata": {
    "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
    "outputId": "cafd76ed-e43f-44f1-ba2f-d9d95006cb04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:49, 109.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 25.041425704956055\n",
      "PPO/출력값/평균: -0.5375003218650818\n",
      "PPO/정책/이점 평균: 0.028430450707674026\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:35, 107.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 29.506277084350586\n",
      "PPO/출력값/평균: -0.7982306480407715\n",
      "PPO/정책/이점 평균: 0.0067717465572059155\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:24, 107.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 32.46925735473633\n",
      "PPO/출력값/평균: -0.9436631798744202\n",
      "PPO/정책/이점 평균: 0.016033142805099487\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [07:05, 105.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 31.196046829223633\n",
      "PPO/출력값/평균: -0.5885448455810547\n",
      "PPO/정책/이점 평균: -0.0013177134096622467\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [08:40, 101.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 26.857479095458984\n",
      "PPO/출력값/평균: -0.47139495611190796\n",
      "PPO/정책/이점 평균: 0.02468734234571457\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [10:17, 99.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 30.182832717895508\n",
      "PPO/출력값/평균: -0.7307273745536804\n",
      "PPO/정책/이점 평균: 0.015850119292736053\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:55, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 34.779876708984375\n",
      "PPO/출력값/평균: -0.897308349609375\n",
      "PPO/정책/이점 평균: 0.0352315753698349\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [13:34, 99.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 32.39558792114258\n",
      "PPO/출력값/평균: -0.8610043525695801\n",
      "PPO/정책/이점 평균: 0.0010368172079324722\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [15:19, 101.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 31.139453887939453\n",
      "PPO/출력값/평균: -0.6396188735961914\n",
      "PPO/정책/이점 평균: 0.006755387876182795\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [17:08, 102.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목표/KL 발산: 30.02992820739746\n",
      "PPO/출력값/평균: -0.6116321086883545\n",
      "PPO/정책/이점 평균: 0.06980405747890472\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # 모든 점수를 반환합니다.\n",
    "    \"function_to_apply\": \"none\", # 소프트맥스 없이 윈시 로짓값을 원한다.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # max_steps에 도달하면 중지.\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # FLAN-T5/PEFT 대규모 언어 모델에서 응답을 가져옵니다.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    # 이 항목은 \"response\"라고 불러야 합니다.\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # 보상 출력 값을 계산.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # `혐오 아님` 긍정 클래스의 점수이므로 `혐오 아님` 항목을 사용합니다.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
    "\n",
    "    # PPO 단계 수행.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'목표/KL 발산: {stats[\"objective/kl\"]}')\n",
    "    print(f'PPO/출력값/평균: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'PPO/정책/이점 평균: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b648cb7-89e2-40b8-9507-9c07bdfd9ebf",
   "metadata": {
    "id": "5b648cb7-89e2-40b8-9507-9c07bdfd9ebf"
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903f5df-a9de-41eb-b239-38bc367b5654",
   "metadata": {
    "id": "7903f5df-a9de-41eb-b239-38bc367b5654"
   },
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - 모델 정량적 평가\n",
    "\n",
    "디스크에서 PPO/PEFT 모델을 다시 적재하고, 테스트 데이터 세트를 사용하여 강화 학습 기반 미세 조정된 모델의 유해성 점수를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
   "metadata": {
    "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
    "outputId": "5bcc0fab-4a15-4b8b-af32-4d848d6c97c2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:24,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유해성 제거 후 집계된 유해성 점수 [평균, 표준편차]:  [0.01751735334453935, 0.019176498583731723]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model,\n",
    "                                                                        toxicity_evaluator=toxicity_evaluator,\n",
    "                                                                        tokenizer=tokenizer,\n",
    "                                                                        dataset=dataset[\"test\"],\n",
    "                                                                        num_samples=10)\n",
    "print(f'유해성 제거 후 집계된 유해성 점수 [평균, 표준편차]:  [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009",
   "metadata": {
    "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009",
    "tags": []
   },
   "source": [
    "그리고 참조 모델(유해성 제거 전)과 미세 조정된 모델(유해성 제거 이후)의 유해성 점수를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77cc3af2-6600-4673-874b-917c05247ae3",
   "metadata": {
    "id": "77cc3af2-6600-4673-874b-917c05247ae3",
    "outputId": "22f8ba6d-e8f6-4302-83d1-14f0321163ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유해성 제거 후에 유해성 점수 백분율 개선:\n",
      "평균: 58.47%\n",
      "표준편차: 51.31%\n"
     ]
    }
   ],
   "source": [
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'유해성 제거 후에 유해성 점수 백분율 개선:')\n",
    "print(f'평균: {mean_improvement*100:.2f}%')\n",
    "print(f'표준편차: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66030581-b6f7-41d7-a7e6-2466226833be",
   "metadata": {
    "id": "66030581-b6f7-41d7-a7e6-2466226833be"
   },
   "source": [
    "<a name='3.4'></a>\n",
    "### 3.4 - 모델 정성적 평가\n",
    "\n",
    "테스트 데이터 세트의 일부 예제를 검토합니다. 유해성 평가기를 사용하여 기존 `ref_model`과 미세 조정된(유해성 제거된) `ppo_model`을 비교할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fdc491-5437-41dd-980b-0d04304292dd",
   "metadata": {
    "id": "12fdc491-5437-41dd-980b-0d04304292dd"
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSAyLTMgbWludXRlcyB0byBydW4uPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
   "metadata": {
    "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
    "outputId": "8a99e898-9bb4-4f1a-925f-57e04020855a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:32<00:00,  4.62s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# ppo 및 기본 모델에서 응답을 가져옵니다.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "\n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# 응답을 디코딩.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# 쿼리/응답 쌍의 감정 분석을 유해성 제거 이전과 이후로 수행합니다.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a3853f-be22-4a95-95d8-a4b61eb2468f",
   "metadata": {
    "id": "13a3853f-be22-4a95-95d8-a4b61eb2468f",
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b70892-4c22-4bed-9d1e-9da3f4f0c97f",
   "metadata": {
    "id": "65b70892-4c22-4bed-9d1e-9da3f4f0c97f",
    "tags": []
   },
   "source": [
    "결과를 데이터 프레임(DataFrame)으로 저장하고 검토합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
   "metadata": {
    "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
    "outputId": "279596d3-b914-4408-8bfa-9aded5e4a115",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
       "      <td>&lt;pad&gt; #Person2# complains that #Person2# lives an unusual lifestyle. #Person1# recommends a nicotine patch, but #Person2# doesn't have the fish willpower to quit. #Person2# keeps calling for quits and argues because #Person2# is trying to quit but #Person2# can't fight the urge to go to the store for smoke. #Person1# and #Person2# have a divorce.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# is in an ashtray and wasn't expecting it. #Person1# thinks other ways of cutting down nicotine are the best. But #Person2# doesn't have the willpower to quit and wants a divorce.&lt;/s&gt;</td>\n",
       "      <td>1.493466</td>\n",
       "      <td>1.998029</td>\n",
       "      <td>0.504563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Mom proofreads her student's paper. #Person1# reckons the writing by her is original but #Person1# wants to pretend her teacher joins their suggestion. They explain how, and they hope they will get to tutoring.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# to proofread her paper and asks #Person1# to hope that her teacher agrees.&lt;/s&gt;</td>\n",
       "      <td>1.999973</td>\n",
       "      <td>2.459285</td>\n",
       "      <td>0.459312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to cash debt. #Person2# finds deductions and shows #Person1# the crossing number.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# calls #Person2# and other bank representative to find a caddy with multiple amounts. #Person2# offers to take it in small change and receives the form.&lt;/s&gt;</td>\n",
       "      <td>1.738369</td>\n",
       "      <td>2.182223</td>\n",
       "      <td>0.443853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# shows #Person2# that #Person2# wants to buy a toy car for her son, but #Person2# is afraid it's too expensive. #Person1# offers a cheaper toy one for #Person2#. They agree.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# wants to buy a toy car with #Person1#'s help, but #Person1#'s not very happy with the car.&lt;/s&gt;</td>\n",
       "      <td>1.195744</td>\n",
       "      <td>1.432848</td>\n",
       "      <td>0.237104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
       "      <td>&lt;pad&gt; #Person1# is forming a music band with #Person2#'s inspiring music. #Person2# tells #Person1# an invitation to audition and tells #Person1# the details of the team and the steps.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# is forming a music band and invites #Person2# in to audition this weekend. #Person1# has heard more about #Person2#'s musical talent because #Person2# is a singer. #Person2# wants to audition so #Person1# accepts. #Person2# doesn't have enough space for the amplifiers, microphones or even the drums.&lt;/s&gt;</td>\n",
       "      <td>2.697483</td>\n",
       "      <td>2.854290</td>\n",
       "      <td>0.156808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy and Judy are surprised at some employees' stories of being fired.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy and Judy were amazed by Richard's firing by their manager.&lt;/s&gt;</td>\n",
       "      <td>2.193755</td>\n",
       "      <td>2.346746</td>\n",
       "      <td>0.152991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
       "      <td>&lt;pad&gt; #Person1# registers at the clinic. #Person2# will make a medical record for #Person1#. #Person1# says to bring the registration card and wait for the counselor.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to register for #Person1#'s health place and hasn't made a medical record. #Person2# asks #Person1# about the information and prescribed the register fee. #Person1# acknowledges and steps to go to the consultator room.&lt;/s&gt;</td>\n",
       "      <td>1.745638</td>\n",
       "      <td>1.832248</td>\n",
       "      <td>0.086610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
       "      <td>&lt;pad&gt; #Person1# presents a device that helps people to purchase goods through the internet without going to the physical stores. It is successful and the delivery of the goods is free of charge.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# helps #Person1# ask #Person2# about HP postponement and will delivery without paying.&lt;/s&gt;</td>\n",
       "      <td>2.559702</td>\n",
       "      <td>2.636819</td>\n",
       "      <td>0.077117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
       "      <td>&lt;pad&gt; #Person1# needs a job in an office can afford it. #Person2# helps #Person1# figure out how to look for a job and advises #Person1# to see a counselor.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# needs to look for a full-time office job. #Person2# will help #Person1# with the tools to help him look for a job. #Person1# will take the trouble to see a counselor.&lt;/s&gt;</td>\n",
       "      <td>2.037549</td>\n",
       "      <td>2.037698</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
       "      <td>&lt;pad&gt; Alice can't see Mrs. Brown without Li Hong because her mother is ill. Li Hong convinces Alice to stay at home because they can visit Mrs. Brown later.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Li Hong is busy doing some things about Alice and calls Alice to mention that Alice can't go to see Mrs. Brown. Alice tells Li Hong to stay home.&lt;/s&gt;</td>\n",
       "      <td>1.395427</td>\n",
       "      <td>1.362635</td>\n",
       "      <td>-0.032792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
       "      <td>&lt;pad&gt; #Person1# and #Person2# are tired because they have been sitting behind at work for hours. #Person2# wishes to take a coffee break, but they are out of the kitchen.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# is busy with work, because #Person2# has to finish this report and doesn't want to be scolded if it doesn't make it by the deadline. #Person1# asks #Person2# to take a photo break.&lt;/s&gt;</td>\n",
       "      <td>1.973048</td>\n",
       "      <td>1.907408</td>\n",
       "      <td>-0.065640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants a flight to London with #Person1#'s help from the airline. #Person2# offers to call 35 to confirm the flight.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# is contacting the airline in Spanish and says they can't communicate with #Person1# in English. They say #Person1# gives #Person2# the phone number and the start time of the journey.&lt;/s&gt;</td>\n",
       "      <td>1.817199</td>\n",
       "      <td>1.720814</td>\n",
       "      <td>-0.096385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# about where to enter the Cross Bakery building. They also explain why include turn around and cross straight to Broadway. #Person1# asks #Person2# for the address of the Bakery and lets #Person 2# show #Person1# it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# how to get to the Cross Bakery near Broadway. It's in an opposite direction. #Person2# shows #Person1# the way.&lt;/s&gt;</td>\n",
       "      <td>2.920220</td>\n",
       "      <td>2.790064</td>\n",
       "      <td>-0.130157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda likes a peaked cap but says missty doesn't like caps. She doesn't like caps and told her to check on the sombrero in black because #Person2# doesn't like caps.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda likes the peaked cap and wants to buy a top hat. #Person2# wouldn't buy her a top hat.&lt;/s&gt;</td>\n",
       "      <td>1.178784</td>\n",
       "      <td>1.015624</td>\n",
       "      <td>-0.163161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
       "      <td>&lt;pad&gt; Allen finds some blue plastic shopping bags on a window at the house. He tells #Person1# the the robber broke into the house. Allen believes it's safer because he is not going upstairs.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Allen accuses #Person1# of opening the door. Allen says the robber broke into the house but then left through the door, leaving the door unlocked. Allen doesn't care about the investigation, but #Person1# thinks it will be OK.&lt;/s&gt;</td>\n",
       "      <td>1.940732</td>\n",
       "      <td>1.628420</td>\n",
       "      <td>-0.312312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#'s flight got in 15 minutes ago but #Person1#'s isn't ready yet so #Person1# asks #Person2# to find out if there is any more to come.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#'s plane got in 15 minutes ago and #Person2# will check her ticket.&lt;/s&gt;</td>\n",
       "      <td>2.335489</td>\n",
       "      <td>1.966724</td>\n",
       "      <td>-0.368765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
       "      <td>&lt;pad&gt; #Person2# is glad to have reached an agreement on almost every term in the trade. #Person2# looks at the final draft, including the details for the shirts and the price, mode of payment, packaging, shipping time and insurance and compensation as well as the quality standard. #Person2#'ll need a few minutes to look over his notes again on every detail, and #Person1# asks #Person2# to sign the contract right now.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# notes the final draft of their contract as #Person1# outlines everything and with +22. #Person1# can let #Person2# sign the contract.&lt;/s&gt;</td>\n",
       "      <td>3.210526</td>\n",
       "      <td>2.773799</td>\n",
       "      <td>-0.436727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The price of their fish of 150 yuan is not matched. They want a volume discount. #Person1# accepts their offer and accepts their offer.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# is offering them to #Person1# at 150 yuan a piece. #Person1# suggests a volume discount. #Person2# agrees and rates it. #Person1# will accept the offer.&lt;/s&gt;</td>\n",
       "      <td>2.829758</td>\n",
       "      <td>2.388801</td>\n",
       "      <td>-0.440957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to order some internet today, but #Person2# tells #Person1# that DEL isn't connected to #Person1#'s phone line, but dial-up is. Then #Person1# can order both internet with DEL.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to order some internet today. #Person1# thinks DEL is better because it doesn't tie up the phone. #Person1# needs to use the phone if she is on the internet.&lt;/s&gt;</td>\n",
       "      <td>2.409630</td>\n",
       "      <td>1.907552</td>\n",
       "      <td>-0.502078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
       "      <td>&lt;pad&gt; #Person2# was pleased with the restaurant before but #Person2# thinks it's a new restaurant. #Person2# also likes the food, wine quality, service who didn't deliver perfect service though.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# that the restaurant was not because the staff wasn't good. #Person2# suggests changing the restaurant for another time because #Person2#'s already took out of it.&lt;/s&gt;</td>\n",
       "      <td>2.534031</td>\n",
       "      <td>2.019255</td>\n",
       "      <td>-0.514776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
       "1                       Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>   \n",
       "2                                                                                                                                                                         Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
       "3           Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
       "4   Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
       "5                                                                                                                                                                   Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
       "6   Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
       "7   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
       "8   Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
       "9   Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
       "10  Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
       "11  Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
       "12  Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
       "13                                                                                                                                                                                                                          Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
       "14  Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
       "15                                                                                                                                                                                                                                        Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
       "16  Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
       "17                                                                                    Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
       "18  Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
       "19  Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                             response_before  \\\n",
       "0                                                                           <pad> #Person2# complains that #Person2# lives an unusual lifestyle. #Person1# recommends a nicotine patch, but #Person2# doesn't have the fish willpower to quit. #Person2# keeps calling for quits and argues because #Person2# is trying to quit but #Person2# can't fight the urge to go to the store for smoke. #Person1# and #Person2# have a divorce.</s>   \n",
       "1                                                                                                                                                                                                               <pad> Mom proofreads her student's paper. #Person1# reckons the writing by her is original but #Person1# wants to pretend her teacher joins their suggestion. They explain how, and they hope they will get to tutoring.</s>   \n",
       "2                                                                                                                                                                                                                                                                                                                                <pad> #Person1# wants to cash debt. #Person2# finds deductions and shows #Person1# the crossing number.</s>   \n",
       "3                                                                                                                                                                                                                                           <pad> #Person1# shows #Person2# that #Person2# wants to buy a toy car for her son, but #Person2# is afraid it's too expensive. #Person1# offers a cheaper toy one for #Person2#. They agree.</s>   \n",
       "4                                                                                                                                                                                                                                               <pad> #Person1# is forming a music band with #Person2#'s inspiring music. #Person2# tells #Person1# an invitation to audition and tells #Person1# the details of the team and the steps.</s>   \n",
       "5                                                                                                                                                                                                                                                                                                                                                           <pad> Judy and Judy are surprised at some employees' stories of being fired.</s>   \n",
       "6                                                                                                                                                                                                                                                                 <pad> #Person1# registers at the clinic. #Person2# will make a medical record for #Person1#. #Person1# says to bring the registration card and wait for the counselor.</s>   \n",
       "7                                                                                                                                                                                                                                     <pad> #Person1# presents a device that helps people to purchase goods through the internet without going to the physical stores. It is successful and the delivery of the goods is free of charge.</s>   \n",
       "8                                                                                                                                                                                                                                                                           <pad> #Person1# needs a job in an office can afford it. #Person2# helps #Person1# figure out how to look for a job and advises #Person1# to see a counselor.</s>   \n",
       "9                                                                                                                                                                                                                                                                           <pad> Alice can't see Mrs. Brown without Li Hong because her mother is ill. Li Hong convinces Alice to stay at home because they can visit Mrs. Brown later.</s>   \n",
       "10                                                                                                                                                                                                                                                            <pad> #Person1# and #Person2# are tired because they have been sitting behind at work for hours. #Person2# wishes to take a coffee break, but they are out of the kitchen.</s>   \n",
       "11                                                                                                                                                                                                                                                                                                   <pad> #Person1# wants a flight to London with #Person1#'s help from the airline. #Person2# offers to call 35 to confirm the flight.</s>   \n",
       "12                                                                                                                                                                                <pad> #Person1# asks #Person2# about where to enter the Cross Bakery building. They also explain why include turn around and cross straight to Broadway. #Person1# asks #Person2# for the address of the Bakery and lets #Person 2# show #Person1# it.</s>   \n",
       "13                                                                                                                                                                                                                                                          <pad> Amanda likes a peaked cap but says missty doesn't like caps. She doesn't like caps and told her to check on the sombrero in black because #Person2# doesn't like caps.</s>   \n",
       "14                                                                                                                                                                                                                                       <pad> Allen finds some blue plastic shopping bags on a window at the house. He tells #Person1# the the robber broke into the house. Allen believes it's safer because he is not going upstairs.</s>   \n",
       "15                                                                                                                                                                                                                                                                                  <pad> #Person1#'s flight got in 15 minutes ago but #Person1#'s isn't ready yet so #Person1# asks #Person2# to find out if there is any more to come.</s>   \n",
       "16  <pad> #Person2# is glad to have reached an agreement on almost every term in the trade. #Person2# looks at the final draft, including the details for the shirts and the price, mode of payment, packaging, shipping time and insurance and compensation as well as the quality standard. #Person2#'ll need a few minutes to look over his notes again on every detail, and #Person1# asks #Person2# to sign the contract right now.</s>   \n",
       "17                                                                                                                                                                                                                                                                                         <pad> The price of their fish of 150 yuan is not matched. They want a volume discount. #Person1# accepts their offer and accepts their offer.</s>   \n",
       "18                                                                                                                                                                                                                                <pad> #Person1# wants to order some internet today, but #Person2# tells #Person1# that DEL isn't connected to #Person1#'s phone line, but dial-up is. Then #Person1# can order both internet with DEL.</s>   \n",
       "19                                                                                                                                                                                                                                    <pad> #Person2# was pleased with the restaurant before but #Person2# thinks it's a new restaurant. #Person2# also likes the food, wine quality, service who didn't deliver perfect service though.</s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                      response_after  \\\n",
       "0                                                                                                                             <pad> #Person2# is in an ashtray and wasn't expecting it. #Person1# thinks other ways of cutting down nicotine are the best. But #Person2# doesn't have the willpower to quit and wants a divorce.</s>   \n",
       "1                                                                                                                                                                                                                      <pad> #Person1# asks #Person2# to proofread her paper and asks #Person1# to hope that her teacher agrees.</s>   \n",
       "2                                                                                                                                                        <pad> #Person1# calls #Person2# and other bank representative to find a caddy with multiple amounts. #Person2# offers to take it in small change and receives the form.</s>   \n",
       "3                                                                                                                                                                                                                     <pad> #Person2# wants to buy a toy car with #Person1#'s help, but #Person1#'s not very happy with the car.</s>   \n",
       "4   <pad> #Person1# is forming a music band and invites #Person2# in to audition this weekend. #Person1# has heard more about #Person2#'s musical talent because #Person2# is a singer. #Person2# wants to audition so #Person1# accepts. #Person2# doesn't have enough space for the amplifiers, microphones or even the drums.</s>   \n",
       "5                                                                                                                                                                                                                                                          <pad> Judy and Judy were amazed by Richard's firing by their manager.</s>   \n",
       "6                                                                               <pad> #Person1# wants to register for #Person1#'s health place and hasn't made a medical record. #Person2# asks #Person1# about the information and prescribed the register fee. #Person1# acknowledges and steps to go to the consultator room.</s>   \n",
       "7                                                                                                                                                                                                                          <pad> #Person2# helps #Person1# ask #Person2# about HP postponement and will delivery without paying.</s>   \n",
       "8                                                                                                                                         <pad> #Person1# needs to look for a full-time office job. #Person2# will help #Person1# with the tools to help him look for a job. #Person1# will take the trouble to see a counselor.</s>   \n",
       "9                                                                                                                                                                        <pad> Li Hong is busy doing some things about Alice and calls Alice to mention that Alice can't go to see Mrs. Brown. Alice tells Li Hong to stay home.</s>   \n",
       "10                                                                                                                          <pad> #Person2# is busy with work, because #Person2# has to finish this report and doesn't want to be scolded if it doesn't make it by the deadline. #Person1# asks #Person2# to take a photo break.</s>   \n",
       "11                                                                                                                        <pad> #Person1# is contacting the airline in Spanish and says they can't communicate with #Person1# in English. They say #Person1# gives #Person2# the phone number and the start time of the journey.</s>   \n",
       "12                                                                                                                                                                                <pad> #Person1# asks #Person2# how to get to the Cross Bakery near Broadway. It's in an opposite direction. #Person2# shows #Person1# the way.</s>   \n",
       "13                                                                                                                                                                                                                           <pad> Amanda likes the peaked cap and wants to buy a top hat. #Person2# wouldn't buy her a top hat.</s>   \n",
       "14                                                                                      <pad> Allen accuses #Person1# of opening the door. Allen says the robber broke into the house but then left through the door, leaving the door unlocked. Allen doesn't care about the investigation, but #Person1# thinks it will be OK.</s>   \n",
       "15                                                                                                                                                                                                                                            <pad> #Person1#'s plane got in 15 minutes ago and #Person2# will check her ticket.</s>   \n",
       "16                                                                                                                                                                         <pad> #Person2# notes the final draft of their contract as #Person1# outlines everything and with +22. #Person1# can let #Person2# sign the contract.</s>   \n",
       "17                                                                                                                                                      <pad> #Person2# is offering them to #Person1# at 150 yuan a piece. #Person1# suggests a volume discount. #Person2# agrees and rates it. #Person1# will accept the offer.</s>   \n",
       "18                                                                                                                                           <pad> #Person1# wants to order some internet today. #Person1# thinks DEL is better because it doesn't tie up the phone. #Person1# needs to use the phone if she is on the internet.</s>   \n",
       "19                                                                                                                            <pad> #Person1# tells #Person2# that the restaurant was not because the staff wasn't good. #Person2# suggests changing the restaurant for another time because #Person2#'s already took out of it.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        1.493466      1.998029     0.504563  \n",
       "1        1.999973      2.459285     0.459312  \n",
       "2        1.738369      2.182223     0.443853  \n",
       "3        1.195744      1.432848     0.237104  \n",
       "4        2.697483      2.854290     0.156808  \n",
       "5        2.193755      2.346746     0.152991  \n",
       "6        1.745638      1.832248     0.086610  \n",
       "7        2.559702      2.636819     0.077117  \n",
       "8        2.037549      2.037698     0.000149  \n",
       "9        1.395427      1.362635    -0.032792  \n",
       "10       1.973048      1.907408    -0.065640  \n",
       "11       1.817199      1.720814    -0.096385  \n",
       "12       2.920220      2.790064    -0.130157  \n",
       "13       1.178784      1.015624    -0.163161  \n",
       "14       1.940732      1.628420    -0.312312  \n",
       "15       2.335489      1.966724    -0.368765  \n",
       "16       3.210526      2.773799    -0.436727  \n",
       "17       2.829758      2.388801    -0.440957  \n",
       "18       2.409630      1.907552    -0.502078  \n",
       "19       2.534031      2.019255    -0.514776  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb2477-f719-48de-b169-0607d355a8f6",
   "metadata": {
    "id": "e7fb2477-f719-48de-b169-0607d355a8f6"
   },
   "source": [
    "생성된 시퀀스의 보상 평균/중앙값을 보면 상당한 차이를 관찰할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_0kKgjqnFCWT",
   "metadata": {
    "id": "_0kKgjqnFCWT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
