{"cells":[{"cell_type":"markdown","metadata":{"tags":[],"id":"-smQ37jvlJ9t"},"source":["# 인간 피드백으로 보상 모델 학습하기\n","\n","보상 모델은 특정 리뷰에 대한 선호된 `star_rating`을 가진 인간이 단 주석 데이터 세트로 학습됩니다. 이 모델은 그라운드 트루스(Ground Truth)에서 제공된 인간이 단 주석 데이터를 (리뷰, 별점(star_rating), 순위) 튜플로 만듭니다. 해당 튜플로 강화 학습(RL) 기반 모델의 미세 조정을 위한 보상 점수를 제공합니다.\n","\n","\n","![파이프라인](img/generative_ai_pipeline_rlhf_plus.png)\n","\n","![인간 피드백을 통한 강화 학습(Reinforcement Learning from Human Feedback; RLHF)](img/rlhf_qa.png)\n","\n","![인간이 매긴 순위 데이터를 보상 데이터 세트로 변환하기](img/convert_groundtruth_ranking_data_to_reward_model_dataset_qa.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tab34YRFlJ9w"},"outputs":[],"source":["# question1 response1 response2    0\n","# question1 response1 response3    1\n","# question1 response1 response4    0\n","\n","# question1 response2 response3    0\n","# question1 response2 response4    1\n","\n","# question1 response3 response4    0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8G8GNy-4lJ9x"},"outputs":[],"source":["%pip install --disable-pip-version-check -q \\\n","    transformers==4.26.1 \\\n","    datasets==2.9.0 \\\n","    accelerate==0.17.0 \\\n","    bitsandbytes==0.37.0 \\\n","    promptsource==0.2.3 \\\n","    trl==0.4.1 \\\n","    evaluate==0.4.0"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"PtkRUbN9lJ9y"},"outputs":[],"source":["import boto3\n","import sagemaker\n","import pandas as pd\n","\n","sess = sagemaker.Session()\n","bucket = sess.default_bucket()\n","role = sagemaker.get_execution_role()\n","region = boto3.Session().region_name"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"5VJttsjJlJ9y"},"outputs":[],"source":["import io\n","import json\n","import uuid\n","import time\n","import boto3\n","import botocore\n","\n","# 아마존 파이썬 SDK 클라이언트\n","sagemaker = boto3.client(\"sagemaker\", region)\n","a2i = boto3.client(\"sagemaker-a2i-runtime\")\n","s3 = boto3.client(\"s3\", region)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"bDv26faIlJ9y"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import argparse\n","import pprint\n","from collections import defaultdict\n","\n","import torch\n","import torch.distributed as dist\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data\n","import torch.utils.data.distributed\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import AutoConfig, AutoModelForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"RaKvuEvKlJ9y"},"outputs":[],"source":["%store -r human_feedback_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"AKjHrciZlJ9y"},"outputs":[],"source":["try:\n","    human_feedback_dataset\n","except NameError:\n","    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n","    print(\"[ERROR] Please run the notebooks in the previous section before you continue.\")\n","    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ZtDZHBXvlJ9z","outputId":"4a34df02-a7e3-4615-e46b-5218364e39f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['prompt', 'response', 'ranking'],\n","    num_rows: 3\n","})\n"]}],"source":["print(human_feedback_dataset)"]},{"cell_type":"markdown","metadata":{"id":"rm9ASfnxlJ9z"},"source":["# 인간 선호도 및 정렬 데이터로 보상 모델 학습하기\n","이 모델은 일반적으로 이전 노트북에서 학습된 지도 학습 기반 미세 조정(Ssupervised-fine-tuned; SFT) 모델로부터 초기화된 언어 모델이며, 여기에 이진 분류 레이어를 추가로 배치합니다. 이 보상 모델은 다음 단계에서 강화 학습 모델을 학습하는 데 사용됩니다. 강화 학습 모델은 실제 애플리케이션으로 배포됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3GdAgF5lJ9z"},"outputs":[],"source":["%store -r peft_fine_tuned_with_public_qanda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V80HzqiZlJ9z"},"outputs":[],"source":["try:\n","    peft_fine_tuned_with_public_qanda\n","except NameError:\n","    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n","    print(\"[ERROR] Please run the notebooks in the previous section before you continue.\")\n","    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUl5vNmglJ90","outputId":"8eb5a409-202c-44e4-d0c1-8351391ac0c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["./peft_fine_tuned_with_public_qanda\n"]}],"source":["print(peft_fine_tuned_with_public_qanda)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"CZaOXDr7lJ90"},"outputs":[],"source":["from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union\n","\n","import evaluate\n","import numpy as np\n","import torch.nn as nn\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    HfArgumentParser,\n","    PreTrainedTokenizerBase,\n","    Trainer,\n","    TrainingArguments,\n",")\n","from transformers.utils import PaddingStrategy"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"sM2sxIPwlJ90"},"outputs":[],"source":["from peft import PeftModel\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","base_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-small',\n","                                                   torch_dtype=torch.float16)\n","\n","model = PeftModel.from_pretrained(base_model, peft_fine_tuned_with_public_qanda)\n","tokenizer = AutoTokenizer.from_pretrained(peft_fine_tuned_with_public_qanda)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ft8RCBDGlJ90"},"outputs":[],"source":["# 데이터 세트를 프롬프트 + 응답 쌍으로 변환합니다. 여기서 text_j는 선호되는 프롬프트 + 응답이고, text_k는 다른 응답입니다.\n","def turn_into_text_classification_format(examples):\n","    new_examples = {\"text_j\": [], \"text_k\": []}\n","    print(new_examples)\n","    for prompt, response, ranking in zip(examples[\"prompt\"], examples[\"response\"], examples[\"ranking\"]):\n","        # 할일: 단일 0과 단일 1만 있는지 확인해보기\n","        if len(response) != 2 or len(ranking) != 2 or ranking[0] not in (0, 1) or ranking[1] not in (0, 1):\n","            raise ValueError(\n","                f\"There should be two responses with a ranking that is either 0 or 1. Received {len(response)} responses and {len(ranking)} rankings.\"\n","            )\n","\n","        highest_ranked_response_index = ranking.index(1) # 레이블러가 정의한 대로 보상 1을 가진 응답을 두 응답 목록에서 찾기\n","\n","        new_examples[\"text_j\"].append(\n","            #str(response[highest_ranked_response_index]) + \" \" + tokenizer.bos_token + \" \" + prompt\n","            prompt + \" \" + str(response[highest_ranked_response_index])\n","        )\n","        new_examples[\"text_k\"].append(\n","            #str(response[0 if highest_ranked_response_index == 1 else 1]) + \" \" + tokenizer.bos_token + \" \" + prompt\n","            prompt + \" \" + str(response[0 if highest_ranked_response_index == 1 else 1])\n","        )\n","\n","    return new_examples\n","\n","# 데이터 세트 토큰화.\n","def preprocess_function(examples):\n","    tokenized_j = tokenizer(examples[\"text_j\"], truncation=True)\n","    tokenized_k = tokenizer(examples[\"text_k\"], truncation=True)\n","    return {\n","        \"input_ids_j\": tokenized_j[\"input_ids\"],\n","        \"attention_mask_j\": tokenized_j[\"attention_mask\"],\n","        \"input_ids_k\": tokenized_k[\"input_ids\"],\n","        \"attention_mask_k\": tokenized_k[\"attention_mask\"],\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"colab":{"referenced_widgets":["9e88d7a82e11475eaf792b8b243d0f50","ef5832d7d88a434f939861ba26057e4d","c301a7da651441bea013c172289d8d84","681d7cee0a8d4a5d8f8051d62b0a62b4","061f13f48b4a40649b22b44333aa2c3b","d75ade88bff94f51a21d782f7fd29127"]},"id":"B1fKbTEWlJ91","outputId":"877b8d2e-c5ae-4fb1-f6a7-4847770ca580"},"outputs":[{"name":"stderr","output_type":"stream","text":["num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"]},{"name":"stdout","output_type":"stream","text":["['prompt', 'response', 'ranking']\n","      "]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e88d7a82e11475eaf792b8b243d0f50","version_major":2,"version_minor":0},"text/plain":["#0:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef5832d7d88a434f939861ba26057e4d","version_major":2,"version_minor":0},"text/plain":["#1:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c301a7da651441bea013c172289d8d84","version_major":2,"version_minor":0},"text/plain":["#2:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"]},{"name":"stdout","output_type":"stream","text":["      "]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"681d7cee0a8d4a5d8f8051d62b0a62b4","version_major":2,"version_minor":0},"text/plain":["#0:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"061f13f48b4a40649b22b44333aa2c3b","version_major":2,"version_minor":0},"text/plain":["#2:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d75ade88bff94f51a21d782f7fd29127","version_major":2,"version_minor":0},"text/plain":["#1:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['input_ids_j', 'attention_mask_j', 'input_ids_k', 'attention_mask_k'],\n","    num_rows: 3\n","})\n"]}],"source":["num_proc = 8  # 더 많은 프로세서가 있으면 조정할 수 있습니다. 하지만 8개의 CPU가 없어도 작동해야 합니다.\n","\n","original_columns = human_feedback_dataset.column_names\n","print(original_columns)\n","\n","human_feedback_binary_classification_dataset = human_feedback_dataset.map(turn_into_text_classification_format, batched=True, num_proc=num_proc, remove_columns=original_columns)\n","\n","human_feedback_tokenized_dataset = human_feedback_binary_classification_dataset.map(preprocess_function,\n","                                                                                    batched=True,\n","                                                                                    num_proc=num_proc,\n","                                                                                    remove_columns=[\"text_j\", \"text_k\"])\n","\n","print(human_feedback_tokenized_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"5DBXpALclJ91"},"outputs":[],"source":["# 검증에 사용할 메트릭을 정의.\n","accuracy = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, _ = eval_pred\n","    # 여기서 예측(predictions)는 rewards_j와 rewards_k입니다.\n","    # rewards_j가 rewards_k보다 더 높은 값의 비율을 확인하고자 합니다.\n","    predictions = np.argmax(predictions, axis=0)\n","    labels = np.zeros(predictions.shape)\n","    return accuracy.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"b11mPjc3lJ91"},"outputs":[],"source":["# j vs k 형식으로 데이터를 배치할 수 있는 특별한 데이터 collator를 정의해야 합니다.\n","@dataclass\n","class RewardDataCollatorWithPadding:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        features_j = []\n","        features_k = []\n","        for feature in features:\n","            features_j.append({\"input_ids\": feature[\"input_ids_j\"], \"attention_mask\": feature[\"attention_mask_j\"]})\n","            features_k.append({\"input_ids\": feature[\"input_ids_k\"], \"attention_mask\": feature[\"attention_mask_k\"]})\n","        batch_j = self.tokenizer.pad( # 질문과 대답 쌍\n","            features_j,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        batch_k = self.tokenizer.pad(\n","            features_k,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        batch = {\n","            \"input_ids_j\": batch_j[\"input_ids\"],\n","            \"attention_mask_j\": batch_j[\"attention_mask\"],\n","            \"input_ids_k\": batch_k[\"input_ids\"],\n","            \"attention_mask_k\": batch_k[\"attention_mask\"],\n","            \"return_loss\": True,\n","        }\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"UgbcywM0lJ91","outputId":"7fe63fee-429a-4eed-8429-2acc01d46ab7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["peft_ranking_reward_custom_qanda_model_name = 'roberta-base'\n","peft_ranking_reward_custom_qanda_model = AutoModelForSequenceClassification.from_pretrained(peft_ranking_reward_custom_qanda_model_name, num_labels=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJxKe-y_lJ91","outputId":"f3ffdf66-4dbc-49ea-b040-9b093bf8af46"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:08, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=1, training_loss=0.1703612059354782, metrics={'train_runtime': 10.1913, 'train_samples_per_second': 0.294, 'train_steps_per_second': 0.098, 'total_flos': 0.0, 'train_loss': 0.1703612059354782, 'epoch': 1.0})"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["class RewardTrainer(Trainer):\n","    # 보상 손실을 계산하는 방법을 정의합니다.\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        rewards_j = model(input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n","        rewards_k = model(input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n","        loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()\n","        if return_outputs:\n","            return loss, {\"rewards_j\": rewards_j, \"rewards_k\": rewards_k}\n","        return loss\n","\n","# 인자를 정의 및 파싱\n","local_rank = 0\n","resume_from_checkpoint = False\n","deepspeed = None\n","per_device_train_batch_size = 16\n","per_device_eval_batch_size = 16\n","gradient_accumulation_steps = 4\n","learning_rate = 2e-5\n","weight_decay = 0.001\n","bf16 = False\n","num_train_epochs = 1\n","\n","peft_ranking_reward_custom_qanda_checkpoint = './peft_ranking_reward_model_custom_qanda/'\n","\n","# 학습 인자를 정의합니다. 모델을 적재하기 전에 정의해야 합니다, 특히 DeepSpeed를 사용하는 경우에 그렇습니다.\n","training_args = TrainingArguments(\n","    output_dir=peft_ranking_reward_custom_qanda_checkpoint,\n","    learning_rate=learning_rate,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    weight_decay=weight_decay,\n","#    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","#    deepspeed=deepspeed,\n","#    local_rank=local_rank,\n","    remove_unused_columns=False,\n","    label_names=[],\n",")\n","\n","# 모델 학습\n","trainer = RewardTrainer(\n","    model=peft_ranking_reward_custom_qanda_checkpoint,\n","    args=training_args,\n","    train_dataset=human_feedback_tokenized_dataset, #[\"train\"],\n","#    eval_dataset=tokenized_ds[\"validation\"],\n","    compute_metrics=compute_metrics,\n","    data_collator=RewardDataCollatorWithPadding(tokenizer=tokenizer),\n",")\n","\n","trainer.train(resume_from_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_qW5NjHlJ92","outputId":"c8315887-0113-4cf6-af2e-34515568bd00"},"outputs":[{"data":{"text/plain":["('./rl-ranking-reward-model-custom-dataset/tokenizer_config.json',\n"," './rl-ranking-reward-model-custom-dataset/special_tokens_map.json',\n"," './rl-ranking-reward-model-custom-dataset/tokenizer.json')"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["trainer.save_model(peft_ranking_reward_custom_qanda_checkpoint)\n","tokenizer.save_pretrained(peft_ranking_reward_custom_qanda_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"GjsCSkVGlJ92","outputId":"1e440c66-8f89-4eac-905f-ebc5ff35cbc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stored 'peft_rl_ranking_reward_custom_dataset_model_checkpoint' (str)\n"]}],"source":["%store peft_ranking_reward_custom_qanda_checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"HEoNTllslJ92"},"outputs":[],"source":["peft_ranking_reward_custom_qanda_checkpoint = AutoModelForSequenceClassification.from_pretrained(peft_ranking_reward_custom_qanda_checkpoint, num_labels=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cODPlQ7VlJ92"},"outputs":[],"source":["from transformers import TextClassificationPipeline\n","from transformers import pipeline\n","\n","tokenizer = AutoTokenizer.from_pretrained(peft_ranking_reward_custom_qanda_checkpoint)\n","\n","peft_ranking_reward_custom_qanda_pipeline = pipeline(\"text-classification\", tokenizer=tokenizer, model=peft_ranking_reward_custom_qanda_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guVLopOQlJ92","outputId":"9187e5c9-9008-4eda-8027-9f3b8e341b93"},"outputs":[{"data":{"text/plain":["[{'label': 'LABEL_0', 'score': 0.4745677709579468}]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["question = 'Who was not the President of the United States in 2010?'\n","answer = 'Barack Obama'\n","prompt_and_answer = \"Question: \" + question + \"\\n\\nAnswer: \" + answer + \"\\n\"\n","peft_ranking_reward_custom_qanda_pipeline.predict(prompt_and_answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vK5RCpMHlJ92"},"outputs":[],"source":[]}],"metadata":{"availableInstances":[{"_defaultOrder":0,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.t3.medium","vcpuNum":2},{"_defaultOrder":1,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.t3.large","vcpuNum":2},{"_defaultOrder":2,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.t3.xlarge","vcpuNum":4},{"_defaultOrder":3,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.t3.2xlarge","vcpuNum":8},{"_defaultOrder":4,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5.large","vcpuNum":2},{"_defaultOrder":5,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5.xlarge","vcpuNum":4},{"_defaultOrder":6,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5.2xlarge","vcpuNum":8},{"_defaultOrder":7,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5.4xlarge","vcpuNum":16},{"_defaultOrder":8,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5.8xlarge","vcpuNum":32},{"_defaultOrder":9,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5.12xlarge","vcpuNum":48},{"_defaultOrder":10,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5.16xlarge","vcpuNum":64},{"_defaultOrder":11,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5.24xlarge","vcpuNum":96},{"_defaultOrder":12,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5d.large","vcpuNum":2},{"_defaultOrder":13,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5d.xlarge","vcpuNum":4},{"_defaultOrder":14,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5d.2xlarge","vcpuNum":8},{"_defaultOrder":15,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5d.4xlarge","vcpuNum":16},{"_defaultOrder":16,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5d.8xlarge","vcpuNum":32},{"_defaultOrder":17,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5d.12xlarge","vcpuNum":48},{"_defaultOrder":18,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5d.16xlarge","vcpuNum":64},{"_defaultOrder":19,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5d.24xlarge","vcpuNum":96},{"_defaultOrder":20,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":true,"memoryGiB":0,"name":"ml.geospatial.interactive","supportedImageNames":["sagemaker-geospatial-v1-0"],"vcpuNum":0},{"_defaultOrder":21,"_isFastLaunch":true,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.c5.large","vcpuNum":2},{"_defaultOrder":22,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.c5.xlarge","vcpuNum":4},{"_defaultOrder":23,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.c5.2xlarge","vcpuNum":8},{"_defaultOrder":24,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.c5.4xlarge","vcpuNum":16},{"_defaultOrder":25,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":72,"name":"ml.c5.9xlarge","vcpuNum":36},{"_defaultOrder":26,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":96,"name":"ml.c5.12xlarge","vcpuNum":48},{"_defaultOrder":27,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":144,"name":"ml.c5.18xlarge","vcpuNum":72},{"_defaultOrder":28,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.c5.24xlarge","vcpuNum":96},{"_defaultOrder":29,"_isFastLaunch":true,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g4dn.xlarge","vcpuNum":4},{"_defaultOrder":30,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g4dn.2xlarge","vcpuNum":8},{"_defaultOrder":31,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g4dn.4xlarge","vcpuNum":16},{"_defaultOrder":32,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g4dn.8xlarge","vcpuNum":32},{"_defaultOrder":33,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g4dn.12xlarge","vcpuNum":48},{"_defaultOrder":34,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g4dn.16xlarge","vcpuNum":64},{"_defaultOrder":35,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":61,"name":"ml.p3.2xlarge","vcpuNum":8},{"_defaultOrder":36,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":244,"name":"ml.p3.8xlarge","vcpuNum":32},{"_defaultOrder":37,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":488,"name":"ml.p3.16xlarge","vcpuNum":64},{"_defaultOrder":38,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.p3dn.24xlarge","vcpuNum":96},{"_defaultOrder":39,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.r5.large","vcpuNum":2},{"_defaultOrder":40,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.r5.xlarge","vcpuNum":4},{"_defaultOrder":41,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.r5.2xlarge","vcpuNum":8},{"_defaultOrder":42,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.r5.4xlarge","vcpuNum":16},{"_defaultOrder":43,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.r5.8xlarge","vcpuNum":32},{"_defaultOrder":44,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.r5.12xlarge","vcpuNum":48},{"_defaultOrder":45,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":512,"name":"ml.r5.16xlarge","vcpuNum":64},{"_defaultOrder":46,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.r5.24xlarge","vcpuNum":96},{"_defaultOrder":47,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g5.xlarge","vcpuNum":4},{"_defaultOrder":48,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g5.2xlarge","vcpuNum":8},{"_defaultOrder":49,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g5.4xlarge","vcpuNum":16},{"_defaultOrder":50,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g5.8xlarge","vcpuNum":32},{"_defaultOrder":51,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g5.16xlarge","vcpuNum":64},{"_defaultOrder":52,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g5.12xlarge","vcpuNum":48},{"_defaultOrder":53,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.g5.24xlarge","vcpuNum":96},{"_defaultOrder":54,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.g5.48xlarge","vcpuNum":192},{"_defaultOrder":55,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4d.24xlarge","vcpuNum":96},{"_defaultOrder":56,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4de.24xlarge","vcpuNum":96}],"instance_type":"ml.t3.medium","kernelspec":{"display_name":"Python 3 (Data Science 3.0)","language":"python","name":"python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}