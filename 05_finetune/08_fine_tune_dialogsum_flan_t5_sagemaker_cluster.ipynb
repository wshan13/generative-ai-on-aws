{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세이지메이커 학습 작업을 사용해 대화 요약을 위한 인스트럭션 기반 학습 모델 미세 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주의: 이 노트북을 완료하는 데 약 20분이 소요됩니다.\n",
    "\n",
    "# 잠시 기다려 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "import botocore.config\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra='gaia/1.0'\n",
    ")\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", \n",
    "                            region_name=region, \n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 요구 사항: 이 노트북을 진행하기 전에 `준비` 섹션의 노트북을 성공적으로 실행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    processed_train_data_s3_uri\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the PREPARE section before you continue.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/train\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    processed_validation_data_s3_uri\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the PREPARE section before you continue.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/validation\n"
     ]
    }
   ],
   "source": [
    "print(processed_validation_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    processed_test_data_s3_uri\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the PREPARE section before you continue.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/test\n"
     ]
    }
   ],
   "source": [
    "print(processed_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3에 있는 데이터 세트 지정하기\n",
    "이전 노트북에서 생성한 학습, 검증, 테스트 분할을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/train\n",
      "2023-10-25 19:35:07    2540571 1698262500203.parquet\n",
      "2023-10-25 19:35:07    2545157 1698262503103.parquet\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_data_s3_uri)\n",
    "\n",
    "!aws s3 ls $processed_train_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/validation\n",
      "2023-10-25 19:35:07     150701 1698262500203.parquet\n",
      "2023-10-25 19:35:07     150220 1698262503103.parquet\n"
     ]
    }
   ],
   "source": [
    "print(processed_validation_data_s3_uri)\n",
    "\n",
    "!aws s3 ls $processed_validation_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/test\n",
      "2023-10-25 19:35:07     157115 1698262500203.parquet\n",
      "2023-10-25 19:35:07     153865 1698262503103.parquet\n"
     ]
    }
   ],
   "source": [
    "print(processed_test_data_s3_uri)\n",
    "\n",
    "!aws s3 ls $processed_test_data_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 입력 데이터 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/train', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/validation', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-079002598131/sagemaker-scikit-learn-2023-10-25-19-28-08-587/output/test', 'S3DataDistributionType': 'FullyReplicated'}}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_input_train_data = TrainingInput(s3_data=processed_train_data_s3_uri)\n",
    "s3_input_validation_data = TrainingInput(s3_data=processed_validation_data_s3_uri)\n",
    "s3_input_test_data = TrainingInput(s3_data=processed_test_data_s3_uri)\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAN 모델을 위한 하이퍼파라미터 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint='google/flan-t5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 1 # 더 오랜 기간 동안 학습하고 싶다면 이 값을 늘리세요.\n",
    "learning_rate = 0.00001\n",
    "weight_decay = 0.01\n",
    "train_batch_size = 4\n",
    "validation_batch_size = 4\n",
    "test_batch_size = 4\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.c5.9xlarge\"\n",
    "train_volume_size = 1024\n",
    "input_mode = \"FastFile\"\n",
    "train_sample_percentage = 0.01 # 더 많은 데이터로 학습하고 싶다면 이 값을 늘리세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 추적을 위한 메트릭 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"'train_loss': ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss': ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체크포인트 S3 위치 지정하기\n",
    "이 노트북에는 스팟 인스턴스 학습을 사용합니다. 노드가 교체되면, 새 노드는 최신 체크포인트에서 학습을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-079002598131/checkpoints/13aab899-f629-4e25-a856-0fbfe8dce688/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_prefix = \"checkpoints/{}\".format(str(uuid.uuid4()))\n",
    "checkpoint_s3_uri = \"s3://{}/{}/\".format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세이지메이커에서 실행할 스크립트 설정하기\n",
    "관리형 세이지메이커 서비스에서 모델을 실행할 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36margparse\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mos\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mjson\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mpprint\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mfrom\u001B[39;49;00m \u001B[04m\u001B[36mtransformers\u001B[39;49;00m \u001B[34mimport\u001B[39;49;00m AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, GenerationConfig\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mfrom\u001B[39;49;00m \u001B[04m\u001B[36mdatasets\u001B[39;49;00m \u001B[34mimport\u001B[39;49;00m load_dataset\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mdef\u001B[39;49;00m \u001B[32mlist_files\u001B[39;49;00m(startpath):\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m    \u001B[39;49;00m\u001B[33m\"\"\"Helper function to list files in a directory\"\"\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[34mfor\u001B[39;49;00m root, dirs, files \u001B[35min\u001B[39;49;00m os.walk(startpath):\u001B[37m\u001B[39;49;00m\n",
      "        level = root.replace(startpath, \u001B[33m'\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m).count(os.sep)\u001B[37m\u001B[39;49;00m\n",
      "        indent = \u001B[33m'\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m'\u001B[39;49;00m * \u001B[34m4\u001B[39;49;00m * (level)\u001B[37m\u001B[39;49;00m\n",
      "        \u001B[36mprint\u001B[39;49;00m(\u001B[33m'\u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m/\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m.format(indent, os.path.basename(root)))\u001B[37m\u001B[39;49;00m\n",
      "        subindent = \u001B[33m'\u001B[39;49;00m\u001B[33m \u001B[39;49;00m\u001B[33m'\u001B[39;49;00m * \u001B[34m4\u001B[39;49;00m * (level + \u001B[34m1\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "        \u001B[34mfor\u001B[39;49;00m f \u001B[35min\u001B[39;49;00m files:\u001B[37m\u001B[39;49;00m\n",
      "            \u001B[36mprint\u001B[39;49;00m(\u001B[33m'\u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m.format(subindent, f))\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mdef\u001B[39;49;00m \u001B[32mparse_args\u001B[39;49;00m():\u001B[37m\u001B[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--train_data\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_CHANNEL_TRAIN\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--validation_data\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_CHANNEL_VALIDATION\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--test_data\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_CHANNEL_TEST\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--output_dir\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_OUTPUT_DIR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--hosts\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mlist\u001B[39;49;00m, default=json.loads(os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_HOSTS\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m]))\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--current_host\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_CURRENT_HOST\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--num_gpus\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_NUM_GPUS\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--checkpoint_base_path\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=\u001B[33m\"\u001B[39;49;00m\u001B[33m/opt/ml/checkpoints\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--train_batch_size\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m128\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--validation_batch_size\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m256\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--test_batch_size\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m256\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--epochs\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m2\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--weight_decay\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m, default=\u001B[34m0.01\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--learning_rate\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m, default=\u001B[34m0.00003\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--train_sample_percentage\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m, default=\u001B[34m0.01\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--model_checkpoint\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=\u001B[34mNone\u001B[39;49;00m)    \u001B[37m\u001B[39;49;00m\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--output_data_dir\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_OUTPUT_DATA_DIR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m])  \u001B[37m# This is unused\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33m\"\u001B[39;49;00m\u001B[33mArgs:\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(args)\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "    env_var = os.environ\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33m\"\u001B[39;49;00m\u001B[33mEnvironment Variables:\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    pprint.pprint(\u001B[36mdict\u001B[39;49;00m(env_var), width=\u001B[34m1\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[34mreturn\u001B[39;49;00m args\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "\u001B[34mif\u001B[39;49;00m \u001B[31m__name__\u001B[39;49;00m == \u001B[33m\"\u001B[39;49;00m\u001B[33m__main__\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m:\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# parse arguments\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    args = parse_args()\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# load the tokenizer and model\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(args.model_checkpoint)\u001B[37m\u001B[39;49;00m\n",
      "    model = AutoModelForSeq2SeqLM.from_pretrained(args.model_checkpoint)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# explore the input files\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    local_data_processed_path = \u001B[33m'\u001B[39;49;00m\u001B[33m/opt/ml/input/data\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33m'\u001B[39;49;00m\u001B[33mListing all input data files...\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    list_files(local_data_processed_path)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# load the dataset\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33mf\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mloading dataset from: \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mlocal_data_processed_path\u001B[33m}\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    tokenized_dataset = load_dataset(\u001B[37m\u001B[39;49;00m\n",
      "        local_data_processed_path,\u001B[37m\u001B[39;49;00m\n",
      "        data_files={\u001B[33m'\u001B[39;49;00m\u001B[33mtrain\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: \u001B[33m'\u001B[39;49;00m\u001B[33mtrain/*.parquet\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mtest\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: \u001B[33m'\u001B[39;49;00m\u001B[33mtest/*.parquet\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m'\u001B[39;49;00m\u001B[33mvalidation\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m: \u001B[33m'\u001B[39;49;00m\u001B[33mvalidation/*.parquet\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m}\u001B[37m\u001B[39;49;00m\n",
      "    ).with_format(\u001B[33m\"\u001B[39;49;00m\u001B[33mtorch\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33mf\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mloaded dataset: \u001B[39;49;00m\u001B[33m{\u001B[39;49;00mtokenized_dataset\u001B[33m}\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# sample the dataset for training\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    skip_inds = \u001B[36mint\u001B[39;49;00m(\u001B[34m1\u001B[39;49;00m / args.train_sample_percentage)\u001B[37m\u001B[39;49;00m\n",
      "    sample_tokenized_dataset = tokenized_dataset.filter(\u001B[34mlambda\u001B[39;49;00m example, indice: indice % skip_inds == \u001B[34m0\u001B[39;49;00m, with_indices=\u001B[34mTrue\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# train the model\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    output_dir = args.checkpoint_base_path\u001B[37m\u001B[39;49;00m\n",
      "    training_args = TrainingArguments(\u001B[37m\u001B[39;49;00m\n",
      "        output_dir=output_dir,\u001B[37m\u001B[39;49;00m\n",
      "        evaluation_strategy=\u001B[33m\"\u001B[39;49;00m\u001B[33mepoch\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "        save_strategy=\u001B[33m\"\u001B[39;49;00m\u001B[33mepoch\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "        learning_rate=args.learning_rate,\u001B[37m\u001B[39;49;00m\n",
      "        num_train_epochs=args.epochs,\u001B[37m\u001B[39;49;00m\n",
      "        per_device_train_batch_size=args.train_batch_size,\u001B[37m\u001B[39;49;00m\n",
      "        per_device_eval_batch_size=args.validation_batch_size,\u001B[37m\u001B[39;49;00m\n",
      "        weight_decay=args.weight_decay,\u001B[37m\u001B[39;49;00m\n",
      "    )\u001B[37m\u001B[39;49;00m\n",
      "    trainer = Trainer(\u001B[37m\u001B[39;49;00m\n",
      "        model=model,\u001B[37m\u001B[39;49;00m\n",
      "        args=training_args,\u001B[37m\u001B[39;49;00m\n",
      "        train_dataset=sample_tokenized_dataset[\u001B[33m'\u001B[39;49;00m\u001B[33mtrain\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m],\u001B[37m\u001B[39;49;00m\n",
      "        eval_dataset=sample_tokenized_dataset[\u001B[33m'\u001B[39;49;00m\u001B[33mvalidation\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m]\u001B[37m\u001B[39;49;00m\n",
      "    )\u001B[37m\u001B[39;49;00m\n",
      "    trainer.train()\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# save the model\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    transformer_fine_tuned_model_path = os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_MODEL_DIR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m]\u001B[37m\u001B[39;49;00m\n",
      "    os.makedirs(transformer_fine_tuned_model_path, exist_ok=\u001B[34mTrue\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mSaving the final model to: transformer_fine_tuned_model_path=\u001B[39;49;00m\u001B[33m{\u001B[39;49;00mtransformer_fine_tuned_model_path\u001B[33m}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    model.save_pretrained(transformer_fine_tuned_model_path)\u001B[37m\u001B[39;49;00m\n",
      "    tokenizer.save_pretrained(transformer_fine_tuned_model_path)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m# Copy inference.py and requirements.txt to the code/ directory for model inference\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m#   Note: This is required for the SageMaker Endpoint to pick them up.\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[37m#         This appears to be hard-coded and must be called code/\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "    local_model_dir = os.environ[\u001B[33m\"\u001B[39;49;00m\u001B[33mSM_MODEL_DIR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m]\u001B[37m\u001B[39;49;00m\n",
      "    inference_path = os.path.join(local_model_dir, \u001B[33m\"\u001B[39;49;00m\u001B[33mcode/\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33m\"\u001B[39;49;00m\u001B[33mCopying inference source files to \u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m.format(inference_path))\u001B[37m\u001B[39;49;00m\n",
      "    os.makedirs(inference_path, exist_ok=\u001B[34mTrue\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    os.system(\u001B[33m\"\u001B[39;49;00m\u001B[33mcp inference.py \u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m.format(inference_path))\u001B[37m\u001B[39;49;00m\n",
      "    os.system(\u001B[33m'\u001B[39;49;00m\u001B[33mcp requirements.txt \u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m.format(inference_path))\u001B[37m\u001B[39;49;00m\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33mf\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m\u001B[33mFiles in inference code path \u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33m{\u001B[39;49;00minference_path\u001B[33m}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "    list_files(inference_path)\u001B[37m\u001B[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,        \n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"validation_batch_size\": validation_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"model_checkpoint\": model_checkpoint,\n",
    "        \"train_sample_percentage\": train_sample_percentage,\n",
    "    },\n",
    "    input_mode=input_mode,\n",
    "    metric_definitions=metrics_definitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 세이지메이커에서 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-25-19-41-48-426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs={\"train\": s3_input_train_data, \"validation\": s3_input_validation_data, \"test\": s3_input_test_data},\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name: pytorch-training-2023-10-25-19-41-48-426\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print(\"Training Job Name: {}\".format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518/197746413.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-west-2#/jobs/pytorch-training-2023-10-25-19-41-48-426\">Training Job</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(\n",
    "            region, training_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518/4162796959.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-west-2#logStream:group=/aws/sagemaker/TrainingJobs;prefix=pytorch-training-2023-10-25-19-41-48-426;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\n",
    "            region, training_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518/728904872.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-west-2-079002598131/pytorch-training-2023-10-25-19-41-48-426/?region=us-west-2&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>'.format(\n",
    "            bucket, training_job_name, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-10-25 19:41:49 Starting - Starting the training job.\n",
      "2023-10-25 19:42:03 Starting - Preparing the instances for training..............\n",
      "2023-10-25 19:43:18 Downloading - Downloading input data....\n",
      "2023-10-25 19:43:43 Training - Downloading the training image..........................\n",
      "2023-10-25 19:45:59 Training - Training image download completed. Training in progress...........................................\n",
      "2023-10-25 19:49:35 Uploading - Uploading generated training model..\n",
      "2023-10-25 19:49:51 Completed - Training job completed\n",
      "CPU times: user 568 ms, sys: 69.2 ms, total: 637 ms\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.latest_training_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미세 조정된 모델을 실시간 엔드포인트에 배포하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-west-2-079002598131/pytorch-training-2023-10-25-19-41-48-426/output/model.tar.gz), script artifact (src), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-west-2-079002598131/pytorch-training-2023-10-25-19-49-54-208/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2023-10-25-19-49-54-208\n",
      "INFO:sagemaker:Creating endpoint-config with name summary-tuned-2023-10-25-19-41-48-426\n",
      "INFO:sagemaker:Creating endpoint with name summary-tuned-2023-10-25-19-41-48-426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "sm_model = estimator.create_model(\n",
    "    entry_point='inference.py',\n",
    "    source_dir='src',\n",
    ")\n",
    "endpoint_name = training_job_name.replace('pytorch-training', 'summary-tuned')\n",
    "predictor = sm_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세이지메이커 엔드포인트에서 미세 조정된 모델로 제로샷 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"\"\"Summarize the following conversation.\n",
    "\n",
    "#Person1#: Tom, I've got good news for you.\n",
    "#Person2#: What is it?\n",
    "#Person1#: Haven't you heard that your novel has won The Nobel Prize?\n",
    "#Person2#: Really? I can't believe it. It's like a dream come true. I never expected that I would win The Nobel Prize!\n",
    "#Person1#: You did a good job. I'm extremely proud of you.\n",
    "#Person2#: Thanks for the compliment.\n",
    "#Person1#: You certainly deserve it. Let's celebrate!\n",
    "\n",
    "Summary:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom's novel has won the Nobel Prize.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker import Predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "response = predictor.predict(zero_shot_prompt,\n",
    "        {\n",
    "            \"ContentType\": \"application/x-text\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        },\n",
    ")\n",
    "response_json = json.loads(response.decode('utf-8'))\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엔드포인트 종료하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
