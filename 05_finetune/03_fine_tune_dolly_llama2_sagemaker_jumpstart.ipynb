{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2ee7fb-e888-4e38-a349-c7c40dfd2963",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": "# 아마존 세이지메이커 점프스타트에서 Llama 2 모델 미세 조정하기"
  },
  {
   "cell_type": "code",
   "id": "85addd9d-ec89-44a7-9fb5-9bc24fe9993b",
   "metadata": {
    "tags": []
   },
   "source": [
    "%pip install -U sagemaker==2.202.1 datasets==2.15.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13274b9b-87bd-4090-a6aa-294570c31e0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 사전 훈련된 모델 배포\n",
    "\n",
    "---\n",
    "\n",
    "먼저 Llama 2 모델을 세이지메이커 엔드포인트로 베포합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "97e1d98f",
   "metadata": {
    "jumpStartAlterations": [
     "modelIdVersion"
    ],
    "tags": []
   },
   "source": [
    "model_id, model_version = \"meta-textgeneration-llama-2-7b\", \"2.*\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1722b230-b7bc-487f-b4ee-98ca42848423",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "pretrained_model = JumpStartModel(model_id=model_id, model_version=model_version)\n",
    "pretrained_predictor = pretrained_model.deploy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3c978645-25ae-48a7-9512-32a43d91dcef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 미세 조정을 위한 데이터 세트 준비\n",
    "\n",
    "---\n",
    "\n",
    "데이터 세트를 도메인 적응 형식 또는 명령어 조정 형식으로 미세 조정할 수 있습니다. 자세한 내용은 [데이터 세트 지침](#Dataset-instruction) 섹션을 참조하세요. 이 실습에서는 명령어 조정 형식의 Dolly 데이터 세트 일부를 사용합니다. [Dolly 데이터 세트](https://huggingface.co/datasets/databricks/databricks-dolly-15k)는 질문 응답, 요약, 정보 추출 등 다양한 범주에 대해 약 15,000개의 명령어-응답 항목을 포함하고 있으며, Apache 2.0 라이선스 하에 제공됩니다. 우리는 미세조정을 위해 요약 예제를 선택할 것입니다.\n",
    "\n",
    "훈련 데이터는 각 줄이 하나의 데이터 샘플을 나타내는 딕셔너리인 JSON 라인 (.jsonl) 형식으로 되어 있습니다. 모든 훈련 데이터는 하나의 폴더에 있어야 하지만, 여러 개의 jsonl 파일에 저장할 수 있습니다. 또한, 입력과 출력 형식을 설명하는 template.json 파일을 훈련 폴더에 포함할 수 있습니다.\n",
    "\n",
    "비정형 데이터 세트(텍스트 파일 모음)으로 모델을 훈련시키려면 부록의 [도메인 적응 데이터 세트 형식으로 미세조정 예제](#Example-fine-tuning-with-Domain-Adaptation-dataset-format) 섹션을 참조하세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "6dd20a0d-15a5-49b0-a330-a75755d046ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dolly_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "\n",
    "# 질문 응답이나 정보 추출을 위해 훈련하려면 다음 줄에서 예제[\"category\"] == \"closed_qa\"/\"information_extraction\"으로 조건문을 변경할 수 있습니다.\n",
    "summarization_dataset = dolly_dataset.filter(lambda example: example[\"category\"] == \"summarization\")\n",
    "summarization_dataset = summarization_dataset.remove_columns(\"category\")\n",
    "\n",
    "# 데이터 세트를 두 개로 분리하여 테스트 데이터는 마지막 모델 평가에 사용합니다.\n",
    "train_and_test_dataset = summarization_dataset.train_test_split(test_size=0.1)\n",
    "train_and_test_dataset[\"test\"][0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8017c4ef-eb89-4da6-8e28-c800adbfc4b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 엔드포인트 호출하기\n",
    "\n",
    "---\n",
    "\n",
    "다음으로 몇 가지 샘플 쿼리를 사용하여 엔드포인트를 호출합니다. 이후에 이 노트북에서는 해당 모델을 사용자 정의 데이터 세트로 미세 조정하고, 미세 조정된 모델을 사용하여 추론을 수행합니다. 또한 사전 훈련된 모델과 미세 조정된 모델을 통해 얻은 결과를 비교합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "b795a085-048f-42b2-945f-0cd339c1cf91",
   "metadata": {
    "tags": []
   },
   "source": [
    "def print_response(payload, response):\n",
    "    print(payload[\"inputs\"])\n",
    "    print(f\"> {response[0]['generation']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09434cdf-1493-4160-9caf-132780bf5940",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_dataset = train_and_test_dataset[\"test\"]\n",
    "\n",
    "inputs, ground_truth_responses, responses_before_finetuning, responses_after_finetuning = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "def predict_and_print(datapoint):\n",
    "    # 명령어 기반 미세 조정을 위해 입력과 출력 사이에 특별한 키를 삽입합니다.\n",
    "    input_output_demarkation_key = \"\\n\\n### Response:\\n\"\n",
    "\n",
    "    prompt = f'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{datapoint[\"instruction\"]}\\n\\n### Input:\\n{datapoint[\"context\"]}\\n\\n',\n",
    "    \n",
    "    payload = {\n",
    "        \"inputs\": prompt[0] + input_output_demarkation_key,\n",
    "        \"parameters\": {\"max_new_tokens\": 100},\n",
    "    }\n",
    "\n",
    "    pretrained_response = pretrained_predictor.predict(\n",
    "        payload, custom_attributes=\"accept_eula=true\"\n",
    "    )\n",
    "\n",
    "    print_response(payload, pretrained_response)\n",
    "\n",
    "\n",
    "for i, datapoint in enumerate(test_dataset.select(range(5))):\n",
    "    predict_and_print(datapoint)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a22171b1-1cec-4cec-9ce4-db62761633d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 데이터 세트 S3에 업로드하기\n",
    "\n",
    "---\n",
    "\n",
    "준비된 데이터 세트를 미세 조정에 사용할 수 있도록 S3에 업로드합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9fbf002-3ee3-4cc8-8fce-871939f1bd19",
   "metadata": {
    "tags": []
   },
   "source": [
    "train_and_test_dataset[\"train\"][0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5614aa66-680b-46d0-a3bc-da5ca1319d81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 훈련에 사용할 수 있도록 훈련 데이터를 로컬 파일로 저장합니다.\n",
    "local_data_file = \"finetuning.jsonl\"\n",
    "train_and_test_dataset[\"train\"].to_json(local_data_file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e1ee29a-8439-4788-8088-35a433fe2110",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "import sagemaker\n",
    "import random\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "train_data_location = f\"s3://{bucket}/finetuning/dolly_dataset\"\n",
    "\n",
    "S3Uploader.upload(local_data_file, train_data_location)\n",
    "print(f\"훈련 데이터: {train_data_location}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b2e5489-33dc-4623-92da-f6fc97bd25ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "다음으로 훈련 작업에서 데이터를 명령어/입력 형식으로 사용하기 위한 프롬프트 템플릿을 생성합니다. (이번 예제에서는 모델을 명령어 기반 미세 조정하므로 해당 형식을 사용합니다.) 또한 배포된 엔드포인트에서 추론할 때 사용할 프롬프트 템플릿도 생성합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "90451114-7cf5-445c-88e3-02ccaa5d3a4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "import json\n",
    "\n",
    "template = {\n",
    "    \"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{context}\\n\\n\",\n",
    "    \"completion\": \"{response}\",\n",
    "}\n",
    "with open(\"template.json\", \"w\") as f:\n",
    "    json.dump(template, f)\n",
    "    \n",
    "S3Uploader.upload(\"template.json\", train_data_location)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "011b28f9-b752-4ab9-a8a6-73b7c7ddb486",
   "metadata": {
    "tags": []
   },
   "source": [
    "!aws s3 ls --recursive $train_data_location"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86e61340-bc81-477d-aaf1-f37e8c554863",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 모델 훈련하기\n",
    "\n",
    "---\n",
    "\n",
    "다음으로 Dolly의 요약 데이터 세트를 사용하여 Llama 2 7B 모델을 미세 조정합니다. 미세 조정 스크립트는 [이 레포지토리](https://github.com/facebookresearch/llama-recipes/tree/main)에서 제공하는 스크립트를 기반으로 합니다. 미세 조정 스크립트에 대해 자세히 알아보려면 [5. 미세조정 방법에 대한 몇 가지 참고 사항](#5.-Few-notes-about-the-fine-tuning-method) 섹션을 확인하세요. 지원되는 하이퍼파라미터와 기본값 목록은 [3. 미세조정을 위한 지원되는 하이퍼파라미터](#3.-Supported-Hyper-parameters-for-fine-tuning) 섹션을 참조하세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a71087e-9c9e-42d7-999e-5f3fac07bc4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    instance_count=2,\n",
    "    environment={\"accept_eula\": \"true\"}\n",
    ")\n",
    "\n",
    "# 기본적으로 명령어 기반 조정은 비활성화 되어있습니다. 따라서 명령어 기반 조정 데이터 세트를 사용하려면\n",
    "estimator.set_hyperparameters(instruction_tuned=\"True\", \n",
    "                              epoch=\"5\", \n",
    "                              max_input_length=\"1024\")\n",
    "estimator.fit({\"training\": train_data_location})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e9decbf-08c6-4cb4-8644-4a96afb5bebf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 미세조정된 모델 배포하기\n",
    "\n",
    "---\n",
    "\n",
    "다음으로 미세 조정된 모델을 배포합니다. 이후 미세 조정된 모델과 사전 훈련된 모델의 성능을 비교합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "016e591b-63f8-4e0f-941c-4b4e0b9dc6fc",
   "metadata": {},
   "source": [
    "finetuned_predictor = estimator.deploy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb57904a-9631-45fe-bc3f-ae2fbb992960",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 사전 훈련된 모델과 미세 조정된 모델 평가하기\n",
    "\n",
    "---\n",
    "\n",
    "다음으로 테스트 데이터를 사용하여 미세 조정된 모델의 성능을 평가하고 이를 사전 훈련된 모델과 비교합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "87085bf6-dc7e-46f3-8563-d2e4aafd0820",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "test_dataset = train_and_test_dataset[\"test\"]\n",
    "\n",
    "inputs, ground_truth_responses, responses_before_finetuning, responses_after_finetuning = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "def predict_and_print(datapoint):\n",
    "    # 명령어 기반 미세 조정을 위해 입력과 출력 사이에 특별한 키를 삽입합니다.\n",
    "    input_output_demarkation_key = \"\\n\\n### Response:\\n\"\n",
    "\n",
    "    prompt = f'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{datapoint[\"instruction\"]}\\n\\n### Input:\\n{datapoint[\"context\"]}\\n\\n',\n",
    "    \n",
    "    payload = {\n",
    "        \"inputs\": prompt[0] + input_output_demarkation_key,\n",
    "        \"parameters\": {\"max_new_tokens\": 100},\n",
    "    }\n",
    "    inputs.append(payload[\"inputs\"])\n",
    "    ground_truth_responses.append(datapoint[\"response\"])\n",
    "\n",
    "    pretrained_response = pretrained_predictor.predict(\n",
    "        payload, custom_attributes=\"accept_eula=true\"\n",
    "    )\n",
    "    responses_before_finetuning.append(pretrained_response[0][\"generation\"])\n",
    "\n",
    "    finetuned_response = finetuned_predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "    responses_after_finetuning.append(finetuned_response[0][\"generation\"])\n",
    "\n",
    "\n",
    "try:\n",
    "    for i, datapoint in enumerate(test_dataset.select(range(5))):\n",
    "        predict_and_print(datapoint)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Inputs\": inputs,\n",
    "            \"Ground Truth\": ground_truth_responses,\n",
    "            \"Response from non-finetuned model\": responses_before_finetuning,\n",
    "            \"Response from fine-tuned model\": responses_after_finetuning,\n",
    "        }\n",
    "    )\n",
    "    display(HTML(df.to_html()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6b0a0f5-ef34-40db-8ab7-c24a5d14b525",
   "metadata": {},
   "source": "### 리소스 정리하기"
  },
  {
   "cell_type": "code",
   "id": "d73ab2da-d00f-46db-90eb-81812898653b",
   "metadata": {},
   "source": [
    "# # 리소스 삭제\n",
    "# pretrained_predictor.delete_model()\n",
    "# pretrained_predictor.delete_endpoint()\n",
    "# finetuned_predictor.delete_model()\n",
    "# finetuned_predictor.delete_endpoint()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "759ce98f-a35a-4c64-9fae-50894b5e9f37",
   "metadata": {
    "tags": []
   },
   "source": "# 부록"
  },
  {
   "cell_type": "markdown",
   "id": "7d1c8c86-bfe2-4828-a7aa-dbd7a5ee075f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 지원되는 추론 매개변수\n",
    "\n",
    "---\n",
    "이 모델은 다음과 같은 추론 페이로드 매개변수를 지원합니다:\n",
    "\n",
    "* **max_new_tokens:** 모델은 출력 길이(입력 컨텍스트 길이를 제외한)가 max_new_tokens에 도달할 때까지 텍스트를 생성합니다. 이 값은 반드시 양의 정수여야 합니다.\n",
    "* **temperature:** 출력의 무작위성을 조절합니다. 높은 temperature 값은 낮은 확률의 단어를 포함한 출력을, 낮은 temperature 값은 높은 확률의 단어를 포함한 출력을 생성합니다. `temperature`가 0이면 탐욕적 디코딩(greedy decoding)이 수행됩니다. 이 값은 반드시 양의 실수여야 합니다.\n",
    "* **top_p:** 텍스트 생성의 각 단계에서 누적 확률 `top_p`에 해당하는 가장 작은 집합의 단어들 중에서 샘플링합니다. 이 값은 0과 1 사이의 실수여야 합니다.\n",
    "* **return_full_text:** True로 설정하면, 입력 텍스트가 생성된 출력 텍스트의 일부가 됩니다. 이 값은 반드시 불(boolean)이어야 하며, 기본값은 False입니다.\n",
    " \n",
    "엔드포인트를 호출할 때 위에 언급된 매개변수의 하위 집합을 지정할 수 있습니다.\n",
    "\n",
    "\n",
    "### 참고 사항\n",
    "- `max_new_tokens`가 정의되지 않은 경우, 모델은 최대 4,000개의 전체 토큰까지 생성할 수 있습니다. 이 경우 엔드포인트 쿼리 시간 초과 오류가 발생할 수 있으므로, 가능한 경우 `max_new_tokens`를 설정하는 것이 좋습니다. 7B, 13B, 70B 모델에 대해서는 각각 `max_new_tokens`를 최대 1500, 1000, 500 이하로 설정하고, 총 토큰 수를 4,000개 이하로 유지하는 것을 권장합니다.\n",
    "- 이 모델은 4,000개의 컨텍스트 길이를 지원하기 위해 배치 크기를 1로 제한하고 있습니다. 더 큰 배치 크기를 사용하는 페이로드는 추론 전에 엔드포인트 오류가 발생합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7e4f8-970f-4a1d-b6ee-86bc77b8b9a9",
   "metadata": {},
   "source": [
    "### 미세 조정을 위해 지원되는 하이퍼파라미터\n",
    "\n",
    "---\n",
    "\n",
    "- epoch: 미세 조정 알고리즘이 훈련 데이터 세트를 통과하는 횟수입니다. 1보다 큰 정수여야 합니다. 기본값: 5\n",
    "- learning_rate: 각 배치의 훈련 예제를 처리한 후 모델 가중치가 업데이트되는 속도입니다. 0보다 큰 양의 실수여야 합니다. 기본값: 1e-4\n",
    "- instruction_tuned: 모델을 명령어로 훈련할지 여부입니다. 'True' 또는 'False' 이어야 합니다. 기본값: 'False'\n",
    "- per_device_train_batch_size: 훈련을 위한 GPU 코어/CPU 당 배치 크기입니다. 양의 정수여야 합니다. 기본값: 4\n",
    "- per_device_eval_batch_size: 평가를 위한 GPU 코어/CPU당 배치 크기입니다. 양의 정수여야 합니다. 기본값: 1\n",
    "- max_train_samples: 디버깅 목적 또는 더 빠른 훈련을 위해 훈련 예제의 수를 이 값으로 줄입니다. -1은 모든 훈련 샘플을 사용하는 것을 의미합니다. 양의 정수 또는 -1이어야 합니다. 기본값: -1 \n",
    "- max_val_samples: 디버깅 목적 또는 더 빠른 훈련을 위해 검증 예제의 수를 이 값으로 줄입니다. -1은 모든 검증 샘플을 사용하는 것을 의미합니다. 양의 정수 또는 -1이어야 합니다. 기본값: -1 \n",
    "- max_input_length: 토큰화 후의 입력 시퀀스의 최대 길이입니다. 이 길이를 초과하는 시퀀스는 잘립니다. -1로 설정하면, max_input_length는 1024와 토크나이저에 의해 정의된 모델의 최대 길이 중 더 작은 값으로 설정됩니다. 양의 값으로 설정하면, max_input_length는 제공된 값과 토크나이저에 의해 정의된 모델의 최대 길이 중 더 작은 값으로 설정됩니다. 양의 정수 또는 -1이어야 합니다. 기본값: -1 \n",
    "- validation_split_ratio: 검증 채널이 없는 경우, 훈련 데이터에서 훈련-검증 분할 비율입니다. 0과 1 사이여야 합니다. 기본값: 0.2 \n",
    "- train_data_split_seed: 검증 데이터가 없는 경우, 알고리즘이 사용하는 훈련 데이터와 검증 데이터를 무작위로 분할하는 것을 고정합니다. 정수여야 합니다. 기본값: 0\n",
    "- preprocessing_num_workers: 전처리를 위해 사용할 프로세스의 수입니다. None이면 메인 프로세스를 사용하여 전처리합니다. 기본값: \"None\"\n",
    "- lora_r: Lora R입니다. 양의 정수여야 합니다. 기본값: 8\n",
    "- lora_alpha: Lora Alpha입니다. 양의 정수여야 합니다. 기본값: 32\n",
    "- lora_dropout: Lora Dropout입니다. 0과 1 사이의 양의 실수여야 합니다. 기본값: 0.05 \n",
    "- int8_quantization: True로 설정하면 훈련을 위해 모델이 8비트 정밀도로 로드됩니다. 7B/13B 모델의 기본값: False. 70B 모델의 기본값: True\n",
    "- enable_fsdp: True로 설정하면 완전 분할 데이터 병렬 처리(Fully Sharded Data Parallelism, FSDP)를 사용하여 훈련합니다. 7B/13B 모델의 기본값: True. 70B 모델의 기본값: False\n",
    "\n",
    "참고 사항 1: int8_quantization은 FSDP와 함께 사용할 수 없습니다. 또한, 모든 g5 인스턴스 유형에 대해 int8_quantization = 'False'와 enable_fsdp = 'False' 설정은 CUDA 메모리 문제로 인해 지원되지 않습니다. 따라서, int8_quantization 또는 enable_fsdp 중 하나를 반드시 'True'로 설정하는 것을 권장합니다.\n",
    "\n",
    "참고 사항 2: 모델의 크기 때문에 70B 모델은 어떤 지원 인스턴스 유형에서도 enable_fsdp = 'True' 설정으로 미세 조정할 수 없습니다.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
